\documentclass[12pt, a4paper]{article}

% Pakete
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{csquotes}
\usepackage{helvet} % Schriftart "Arial" 
\usepackage{setspace} % 1,5-zeiliger Zeilenabstand
\usepackage{titlesec} % Für Anpassungen an den Überschriften
\usepackage{geometry} % Für Anpassungen an den Rändern
\usepackage{hyperref} % Für Verlinkungen im Dokument
\usepackage{tocloft} % Für Anpassungen an das Inhaltsverzeichnis
%\usepackage{apacite} % Für Zitate im APA-Stil
\usepackage{color}
\usepackage{transparent}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tablefootnote}
\usepackage{hyperref}
\usepackage{acronym}
\usepackage{caption}
\usepackage{listings}
\usepackage[backend=biber,style=alphabetic]{biblatex}
\addbibresource{literature.bib}
% Quellenverzeichnis einbinden
%\addbibresource{literature.bib}
%\bibliography{literature}
% Pfad SVG Bilder
\graphicspath{{assets/}}
%\bibliography{literature}


% Formatierung
\renewcommand{\familydefault}{\sfdefault} % Schriftart "Arial"
\geometry{left=3cm,right=3cm,top=2.5cm,bottom=2.5cm} % Ränder
\setlength{\parskip}{0.5em} % Abstand zwischen Absätzen
\setstretch{1.5} % 1,5-zeiliger Zeilenabstand
\setcounter{tocdepth}{3} % Inhaltsverzeichnis bis Ebene 3
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}} % Punkte im Inhaltsverzeichnis
\hypersetup{ % Einstellungen für Verlinkungen
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,      
    urlcolor=black,
    citecolor=black,
}
\lstset{language=Python}
\titleformat{\section} % Anpassungen an Überschriftenebene 1
    {\fontsize{14}{16}\bfseries}{\thesection}{0.5em}{}
\titleformat{\subsection} % Anpassungen an Überschriftenebene 2
    {\fontsize{12}{14}\bfseries}{\thesubsection}{0.5em}{}
\titleformat{\subsubsection} % Anpassungen an Überschriftenebene 3
    {\fontsize{12}{14}\itshape}{\thesubsubsection}{0.5em}{}
    
\newcommand*{\fullref}[1]{\hyperref[{#1}]{\autoref*{#1} \textit{\nameref*{#1}}}}

% Dokumentenanfang
\begin{document}

% Titelseite
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        
        \textbf{\LARGE{Prognose über die Stromerzeugung einer Photovoltaikanlage mittels maschinellem Lernen}}
        
        \vspace{0.5cm}
        \Large{Bachelorarbeit}
        
        \vspace{1.5cm}
        \Large{Vorgelegt von}
        
        \vspace{0.5cm}
        \Large{Leopold Julius Schmid}
        
        \vspace{1.5cm}
        \Large{Matrikelnummer: 79776}
        
        \vfill
        
        \Large{Fakultät für Elektronik und Informatik}
        
        \vspace{0.5cm}
        \Large{Hochschule Aalen}
        
        \vspace{1.5cm}
        \Large{Datum}
        
    \end{center}
\end{titlepage}


\newpage

\section*{Erklärung}


\newpage


\section*{Verzeichnis häufig verwendeter Symbole und Abkürzungen}

\begin{acronym}
\acro{api}[API]{Application Programming Interface}
\acro{bmwk}[BMWK]{Bundesministerium für Wirtschaft und Klimaschutz}
\acro{cart}[CART]{Classification and Regression Trees}
\acro{eeg}[EEG]{Erneuerbare-Energien-Gesetz}
\acro{kwp}[kWp]{Kilowattpeak}
\acro{nabeg}[NABEG]{Netzausbaubeschleunigungsgesetz}
\acro{nrel}[NREL]{National Renewable Energy Laboratory}
\acro{pv}[PV]{Photovoltaik}
\acro{stc}[STC]{Standard Test Conditions}
\end{acronym}

\newpage

\tableofcontents


\newpage
\setcounter{section}{0}


\section{Einführung}

% https://deliverypdf.ssrn.com/delivery.php?ID=741072022102025091073125113103087026048056000029024069069006024045033044114095010039039074015127039038088084074028113120004096071122104086004095015124005018003010012023052041098045084086104027117119025110095086024026081088092106122086093064003097016028011065000109108116004064022082122002124&EXT=pdf&INDEX=TRUE

In der größten bisher durchgeführten Studie zur Klimaangst von jungen Menschen sind 45\% der Befragten der Meinung, dass ihre Gefühle bezüglich des Klimawandels ihr tägliches Leben negativ beeinflussen \cite{marks2021young}. Ohne jede Zweifel stellt der Klimawandel uns und die uns nachfolgenden Generationen vor eine nicht zu unterschätzende Herausforderung. Angefangen mit der Tatsache, dass die Diskussion darüber nicht selten eine Spaltung und Polarisierung der Gesellschaft verursacht. Folglich führt die hitzige und emotionale Debatte dazu, dass die gegensätzlichen Lager sich immer weiter voneinander entfernen und somit jegliche Grundlage für eine zielführende Diskussion unwahrscheinlich wird.

Auf der einen Seite werden die Befürchtungen der Anderen für übertrieben, unwichtig und paranoid gehalten. Wissenschaftliche Unsicherheiten werden verwendet, um gesamte Ergebnisse von Studien als unzuverlässig einzustufen. Modelle werden in der Wissenschaft oft vereinfacht, denn die Isolation und Fokussierung auf bestimmte Aspekte kann helfen ein besseres Verständnis von Phänomenen in der Natur zu erlangen. Auf Grund dieser Vereinfachungen werden die Klimamodelle als zu ausdruckslos betitelt, um die Komplexität des Klimas von unserem Planeten widerzuspiegeln. Dementsprechend seien die Schlussfolgerungen aus den Studien unzutreffend. Investitionen mehrerer Milliardenbeträge seien nicht gerechtfertigt und politische Vorgaben schaden dem eigenem Land mehr, als dass sie dem Planeten helfen werden.

Andererseits wird gemahnt, die Ernsthaftigkeit der Situation nicht zu unterschätzen. Gewarnt wird, dass die Konsequenzen des Klimawandels irreversibel seien, weswegen Treibhausgase unverzüglich auf ein Minimum reduziert werden müssen. Um Folgen wie das Abschmelzen der Eisschilde und Gletscher, das Aussterben verschiedenster Tierarten und der Anstieg des Meeresspiegels zu verhindern, spielen erneuerbare Energien eine entscheidende Rolle. Im Gegensatz zu fossilen Energieträgern erzeugen die Erneuerbaren keine oder nur geringste Treibhausgasemissionen. Bis 2030 sollen die regenerativen Energien 80\% des Strombedarfs Deutschlands decken \cite{faz2023wind}. Da die Möglichkeiten der Energieerzeugung in Deutschland durch Wasserkraft und Biomasseverbrennung schon heute nahezu ausgeschöpft sind, bilden Solar- und Windenergie einen wichtigen Grundpfeiler, um die Ausbauziele zu erreichen. 

Ebenso komplex wie die Klimamodelle, die die Verstrickungen verschiedenster Phänomene in unserer Natur berücksichtigen sollen, ist allerdings die Transformation unseres Stromnetzes. In einem Netz, welches dafür ausgelegt wurde, dass wenige größere Kraftwerke Strom einspeisen, werden künftig immer mehr kleinere, dezentrale Kraftwerke mitwirken. Als Folge kommen diverse Herausforderungen auf uns zu. Unter anderem verträgt nicht jedes elektronische Bauteil in einem Niederspannungsnetz Rücklaufstrom. (QUELLE?) Allerdings könnte es genau zu einem solchen Rücklaufstrom kommen, wenn in dem Niederspannungsnetz mehr Strom erzeugt als verbraucht wird. Des Weiteren reagiert ein Stromnetz äußerst empfindlich auf Spannungsschwankungen. Auf Grund dessen müssen Netzbetreiber darauf achten, dass genauso viel Strom verbraucht wie erzeugt wird. Solar- und Windenergie zählen zu den fluktuierenden Energieerzeugern, ergo ist die Stromproduktion nur sehr begrenzt regulierbar und somit nicht an die aktuelle Marktnachfrage anpassbar.

Die Relevanz der Abschlussarbeit basiert auf der Annahme, dass eine genauere Prognose über die erzeugte Strommenge helfen würde das Stromnetz zu stabilisieren und Netzschwankungen, dass heißt das Risiko eines Brown- oder sogar Black-Outs zu minimieren. Anhand der neu gewonnenen Information könnten kurzfristige Stromimporte beziehungsweise -exporte besser reguliert werden. Ebenso wäre es denkbar, dass man für die Industrie und/ oder Endverbraucher mehr Anreize schafft, ihren Stromverbrauch zu einem gewissen Grad anzupassen, wobei mehr Informationen bezüglich der Verfügbarkeit von Strom gleichfalls hilfreich wäre. Zuletzt könnten starke Abweichungen zwischen der Prognose und der tatsächlich erzeugten Strommenge ein Indiz dafür sein, dass die zugrunde liegende Solaranlage eine Wartung benötigt.

% https://zeitung.faz.net/fas/technik-und-motor/2023-05-14/fuenf-am-tag/892835.html

\newpage

\section{Stand der Technik}

Im folgenden soll betrachtet werden, wie das Stromnetz von Deutschland im Moment aufgestellt ist und welche Maßnahmen ergriffen werden müssen, um den Bedarf an Strom zu decken und die Energiewende zu meistern. Zudem gilt es, den in Zukunft zu erwartenden Strombedarf zu analysieren.

\subsection{Strombedarf in Deutschland}
\label{subsec:energy_need}

Im gesamten Jahr 2018 betrug die realisierte Stromerzeugung in Deutschland 543.053.395 MWh, wodurch gute 30 TWh Strom mehr erzeugt als benötigt wurden. 2022 hingegen sank der Bedarf und die Erzeugung auf ungefähr 490.000.000 MWh \cite{ws:smard}.

%https://www.smard.de/home/marktdaten?marketDataAttributes=%7B%22resolution%22:%22year%22,%22from%22:1498773600000,%22to%22:1687471199999,%22moduleIds%22:%5B5000410,1004066,1001226,1001225,1004067,1004068,1001228,1001224,1001223,1004069,1004071,1004070,1001227%5D,%22selectedCategory%22:null,%22activeChart%22:true,%22style%22:%22color%22,%22categoriesModuleOrder%22:%7B%7D,%22region%22:%22DE%22%7D

Tatsache ist jedoch, dass die Dekarbonisierung durch Elektrifizierung unserer Industrie, des Verkehrs als auch des privaten Sektors stattfinden soll, weshalb mit einer deutlichen Zunahme des Strombedarfes zu rechnen ist. Allem voran kommen hierbei Elektroautos und Wärmepumpen zum Einsatz, für deren Betrieb elektrische Energie eine Grundvoraussetzung ist. 

Die Wärmepumpen führen dazu, dass der Stromverbrauch im Winter deutlich steigen wird. Zwar können diese Aggregate im Sommer ebenfalls zum Kühlen verwendet werden, allerdings ist dabei der Stromverbrauch, zumindest bei einem Teil der Wärmepumpen, signifikant geringer. Nämlich reicht der Erdwärmepumpe eine kleine Umwälzpumpe aus, um die niedrigen Temperaturen aus den Tiefen zu holen und damit das Haus zu kühlen. Der Verdichter, der am meisten Strom verbraucht, wird nur von Luft-Wasser-Wärmepumpen zum Kühlen benötigt \cite{faz2023waermepumpe}.

Bei Erd- beziehungsweise Grundwasserwärmepumpen reicht eine kleinere Umwälzpumpe aus, um die notwendige Wärme. (???) 

%https://zeitung.faz.net/fas/wert-wohnen/2023-07-16/wie-kriege-ich-mein-haus-kalt/915655.html

Bis 2030 sollen sich 15 Millionen Elektroautos auf den deutschen Straßen fortbewegen, damit wäre nahezu jedes vierte Auto in Deutschland kein klassischer Verbrenner mehr, sondern von Energie aus Wallboxen abhängig \cite{ws:tagesschau}.
%https://www.tagesschau.de/inland/spitzenrunde-mobilitaet-e-autos-101.html


Schließlich hat sich Deutschland als Ziel gesetzt, bis 2030 65 Prozent weniger Treibhausgase zu emittieren als 1990. Hierzu soll der sich aktuell noch hinter seinen Zielen befindende Verkehrssektor durch eine stärkere Elektrifizierung die gesetzten Vorgaben aufholen.

Um die Klimaneutralität bis 2045 zu erreichen, sollen parallel dazu ab 2024 500.000 neue Wärmepumpen pro Jahr installiert werden \cite{ws:bundesregierung}. Wärmepumpen werden, wie bereits unter \autoref{subsec:energy_need} erwähnt, mit elektrischer Energie betrieben und entziehen der Umweltwärme die Energie, um diese für die Wärmeversorgung von Gebäuden zu verwenden. So kann der Bedarf an fossilen Energieträgern sukzessive heruntergefahren werden.
%https://www.bundesregierung.de/breg-de/aktuelles/kanzler-viessmann-2070096#:~:text=W%C3%A4rmepumpen%20k%C3%B6nnen%20sowohl%20Alt%2D%20als%20auch%20Neubauten%20klimafreundlich%20beheizen.&text=Die%20Bundesregierung%20hat%20sich%20das,weniger%20Treibhausgas%2DEmissionen%20zu%20verursachen.

Das \ac{bmwk} prognostiziert daher für 2030, dass der Bedarf an Strom auf 750 TWh ansteigen wird.

\subsection{Strommix Deutschland}

Laut dem \ac{bmwk} (Stand 1. April 2020) ist Deutschland im Besitz von Stromerzeugungsanlagen mit einer Netto-Nennleistung von effektiv 221,3 Gigawatt. Die Netto-Nennleistung bezeichnet die Energie, die eine Anlage unter Normalbedingungen ohne Beeinträchtigung der Lebensdauer vollbringen kann. Bereits abgezogen ist der Eigenbedarf der Stromerzeugungsanlage. Im Falle einer \ac{pv}-Anlage ist die Brutto-Nennleistung vor allem wegen der Gleich-/ Wechselstromumwandlung höher. 

\begin{figure}
\centering
\def\svgwidth{450pt}
\fontsize{7}{10}\selectfont
\input{assets/Strombedarf_Erzeugung_2022.pdf_tex}
\caption{Stromerzeugung und -bedarf, Deutschland 2022}
\label{fig:stromerzeugung_de_2022}
\end {figure}

Der Anteil der erneuerbaren Energien an Deutschlands Netto-Nennleistung beläuft sich dabei bereits auf mehr als die Hälfte, nämlich 121 Gigawatt. Führend unter den erneuerbaren Energien ist die On- und Offshore-Windenergie, Energie aus \ac{pv}-Anlagen kommt mit 47,3 Gigawatt an zweiter Stelle. Mit 21,2 Prozent spielen sie dementsprechend eine entscheidende Rolle in der Energieversorgung von Deutschland. Dabei ist jedoch zu beachten, dass die verschiedenen Stromerzeuger je nach Jahreszeit eine unterschiedlich wichtige Stellung einnehmen. Während \ac{pv} in der Winterzeit auf einen Bruchteil zurückgeht, erreicht die Windenergie im Winter ihre Maximalwerte, die jedoch selbst in einer wöchentlichen Betrachtung mit stärkeren Schwankungen einhergehen. In \autoref{fig:stromerzeugung_de_2022} ist ersichtlich, dass temporär fast die Hälfte der Stromerzeugung durch Onshore-Windkraftanlagen erzeugt wird. Ebenso ist erkenntlich, dass Deutschland auf den Import von Energie angewiesen ist, wenn eine Flaute aufzieht und die Erneuerbaren weniger Energie als im rechnerischen Durchschnitt erzeugen. Ausschließlich Wasserkraft und Biogasanlagen sind bei den Erneuerbaren in der Lage relativ konstant Energie zu produzieren. Sowohl im Mai als auch Mitte Oktober 2022 konnten konventionelle Energieerzeuger die Diskrepanz nicht ausgleichen, weshalb die internationale Vernetzung des Stromnetzes und dadurch möglichen Importe beziehungsweise Exporte unentbehrlich sind. Schließlich wären die Investitionskosten für Speicherkraftwerke oder Reservekraftwerke, die auch in Dunkelflauten genügend Energie noch erzeugen könnten, weder ökologisch noch ökonomisch tragbar. Für eine gestärkte Versorgungssicherheit ist die Vernetzung elementar. Hilfreich ist, dass die unterschiedlichen geographischen Gegebenheiten der Länder verschiedene Arten der regenerativen Energieerzeugung ermöglichen. So verfügen die Alpenländer und Skandinavien eine erheblich bessere Grundvoraussetzung für die Stromproduktion durch Wasserkraft. So ist das vernetze Stromnetz gegenüber Großwetterlagen, die zum Beispiel die Produktion von Solar- und Windkraftanlagen in nennenswerten Bereichen Europas beeinflussen, weniger anfällig.


\subsection{Aufbau des Stromnetzes}

Auf Grund der geographischen Lage liegt Deutschland äußerst zentral in einem ineinander verstricktem europäischen Stromsystem. Somit nimmt es in Europa eine Schlüsselrolle ein und ist eine Drehscheibe für den Stromfluss innerhalb des Kontinents.

%https://www.bmwk.de/Redaktion/DE/Dossier/strommarkt-der-zukunft.html#:~:text=Aufgrund%20der%20zunehmenden%20Elektrifizierung%20in,2045%20wurde%20im%20Energiewirtschaftsgesetz%20verankert.

Um das Stromnetz genauer zu betrachten, muss zunächst zwischen Hochspannungsnetzen, Mittelspannungsnetzen und Niederspannungsnetzen differenziert werden. Durch die Umwandlung der Spannung auf 60 bis 220 Kilovolt ist der landesweite Transport in den Hochspannungsnetzen des Stroms signifikant effizienter, da durch die höhere Spannung die Stromstärke gesenkt wird \cite{faz2023stromnetz}. Dies vor dem Hintergrund, dass der Leitungsverlust quadratisch mit der Stromstärke zunimmt. Demnach sind Hochspannungsnetze die notwendigen Autobahnen des Stromnetzes. (QUELLE)

Bisher wurden in der öffentliche Debatte insbesondere die großen Stromtrassen thematisiert. Beschwerden, wie Bürgerbeschwerden, dass die Trassen zu nah am eigenen Grundstück wären, führen häufig zu einem schleppenden Ausbau. Keineswegs zu unterschätzen ist jedoch die Wichtigkeit der lokalen Niederspannungsnetze. Die dezentrale Energieerzeugung führt dazu, dass die Energiewende genauso dort stattfinden muss. Leitungen, Trafos und Schaltkästen müssen weiter ausgebaut und erneuert werden. Nicht übertrieben wäre es zu sagen, dass die Energiewende im Verteilernetz stattfindet.

Heutzutage sind Verbraucher längst nicht mehr nur Verbraucher, stattdessen werden viele von ihnen zu sogenannten Prosumenten. Hinter dem Begriff verbergen sich die Wörter Konsument und Produzent. Bereits 2022 gehörten ungefähr 2,2 Millionen private Haushalte zu den eben diesen Prosumenten \cite{ws:destatis}. 


%https://www.destatis.de/DE/Presse/Pressemitteilungen/2022/06/PD22_N037_43.html#:~:text=2020%20hatten%20etwa%201%2C4,Jahr%20der%20Erhebung%20dieser%20Angabe.

%https://zeitung.faz.net/fas/wissenschaft/2023-07-09/eine-frage-der-verteilung/912527.html

\subsection{Schwankungen im Stromnetz}

Dementsprechend ist es für uns unverzichtbar, die Wichtigkeit einer stabilen \linebreak Stromerzeugung richtig einzuschätzen und anhand dessen Maßnahmen zu ergreifen, um Spannungsschwankungen im Netz so weit wie möglich zu reduzieren.

Der stetig schwankende Strombedarf und die ebenso fluktuierende Stromerzeugung führen dazu, dass von einzelnen Ländern in größeren Dimensionen Strom sowohl exportiert als auch importiert werden müssen. Dies hilft dabei, im gesamten Stromnetz die Netzspannung beständig und konstant zu halten. In 2019 konnte Deutschland 72,4 $TWh$ Strom an verschiedene Nachbarländer exportieren und hat im selben Jahr etwa die Hälfte (39,8 $TWh$) davon importiert \cite{ws:bmwk}.
%https://www.bmwk.de/Redaktion/DE/Dossier/strommarkt-der-zukunft.html#:~:text=Aufgrund%20der%20zunehmenden%20Elektrifizierung%20in,2045%20wurde%20im%20Energiewirtschaftsgesetz%20verankert.

Auf Grund von stark schwankendem Verbrauchs der Privathaushalten sowie weiten Teilen der Industrie ist der Strombedarf je nach Uhrzeit unterschiedlich. So ist Tatsache, dass der Strombedarf tagsüber nahezu doppelt so hoch ist im Vergleich zur Nacht. Von Frühling bis in die späten Sommermonate kann der zusätzliche Bedarf häufig durch \ac{pv} gedeckt werden und somit bildet Sonnenenergie eine gute Ergänzung für die anderen Energieerzeuger. 

%Folglich sind Solaranlagen allein ohne Speichermöglichkeiten keineswegs grundlastfähig.

\begin{figure}
\centering
\def\svgwidth{450pt}
\fontsize{7}{10}\selectfont
\input{assets/Strombedarf_Erzeugung_Woche.pdf_tex}
\caption{Realisierte Erzeugung Deutschland im Juli 2022}
\label{fig:stromerzeugung_de_mai}
\end {figure}

\subsubsection{Redispatch}

Zuvor wurde thematisiert, wie wichtig es ist, dass das Stromnetz auf internationaler Ebene miteinander verknüpft ist. Ebenso ist es notwendig, das Netz auf lokaler Ebene zu betrachten. Um die Netzstabilität zu gewährleisten, führen Übertragungsnetzbetreiber sogenanntes \textit{Redispatching} durch. Dabei wird gezielt die Einspeisung von Erzeugungsanlagen gedrosselt, um Überlastungen an Engstellen im Stromnetz zu vermeiden. Da dies äußerst kurzfristig passiert und die zuvor gekaufte mit der tatsächlich erzeugten Strommenge übereinstimmen muss, beauftragen die Netzbetreiber andere Erzeugungsanlagen, die hinter den Engpässen liegen, mehr Strom zu produzieren.

Durch eine Neuerung im \ac{nabeg}  im Jahr 2019 wurde \textit{Redispatching} weiterhin optimiert. Die Neuerung besagt, dass ab Oktober 2021 die Netzbetreiber mehr Erzeugungs- und Speicheranlagen für das Unterbinden von Netzengpässen miteinbeziehen dürfen. Zuvor konnten sich Anlagen mit einer installierten Leistung unter 10 $MW$der Teilnahmepflicht am \textit{Redispatch} entziehen. Der Grenzwert wurde nicht nur auf 100 $kW$ herabgesetzt, des Weiteren sind sämtliche steuerbaren Anlagen, unabhängig von deren installierten Leistung, gleichfalls an der Teilnahme verpflichtet \cite{ws:bmwk}.

%https://www.bmwk.de/Redaktion/DE/Dossier/strommarkt-der-zukunft.html#:~:text=Aufgrund%20der%20zunehmenden%20Elektrifizierung%20in,2045%20wurde%20im%20Energiewirtschaftsgesetz%20verankert.


% https://www.visualcrossing.com/resources/documentation/weather-data/how-to-obtain-solar-radiation-data/

\subsection{Wetter-unabhängige Faktoren}

Bevor der Stromertag einer \ac{pv}Anlage mit Hilfe von künstlicher Intelligenz berechnet werden soll, ist es von immenser Bedeutung die maßgeblichen Faktoren herauszufinden. Wenn ein Modell eingelernt werden soll, können zu viele Faktoren zum \textit{Fluch der Dimensionen} führen. Dieser besagt, dass zu viele Merkmale dazu verleiten, dass Muster und Strukturen sich schwerer erkennen lassen. Die Datenpunkte sind durch die Größe des mehrdimensionalen Raums weiter voneinander entfernt, wodurch die Interpretierbarkeit komplexer wird. Dementsprechend sind die Eingabedaten behutsam auszuwählen.

In Bezug auf die Rahmenparameter der Solaranlage ist die reine Größe selbstverständlich ein maßgeblicher Faktor. Hinzu kommt, dass sich dieses Merkmal für jede \ac{pv}-Anlge individuell stark unterscheidet. Die Dimensionierung der Solaranlage hängt schließlich ebenfalls von verschiedenen Faktoren ab, darunter die verfügbare Fläche am Standort, dem Energiebedarf und dem Verwendungszweck.

\subsubsection{Schatten}

Durch die Aggregation von Metadaten der Solaranlagen könnte man die zuvor genannten Faktoren ebenfalls in das Datenmodell einfließen lassen. Die Komplexität des Modells würde erheblich zunehmen, jedoch wäre das Modell somit auf verschiedene Solaranlagen verallgemeinerbar. Zwei Faktoren überdehnen jedoch nicht nur die Möglichkeiten der Anwendungen von maschinellem Lernen - oder würden die Vorhersagen des Modells zumindest signifikant beeinträchtigen. Des Weiteren stellen sie teilweise eine große Herausforderung beim Schritt der Datenerfassung dar. Erster Faktor ist die Umgebung der Solaranlage, die sich folglich nur auf jeweilige Solaranlage auswirken kann. Umliegende höhere Gebäude, Schornsteine, Hügel und Bäume können Schatten auf die Solarmodule werfen, wodurch die Sonnenstrahlung beeinträchtigt und die Stromproduktion reduziert wird. Gesondert anspruchsvoll wird es dadurch, dass der geworfene Schatten von der Elevation der Sonne abhängig ist. Die Elevation der Sonne wiederum ist von der Jahreszeit abhängig. Die Wahrscheinlichkeit, dass die Solarpanele durch umliegende Strukturen tangiert wird, ist somit im Winter höher. 

\subsubsection{Orientierung}

Der zweite Faktor ist die Orientierung der Solarmodule, womit im Fachjargon der Architektur die Ausrichtung eines Baukörpers nach den Himmelsrichtung gemeint ist. Sofern die Module statisch befestigt sind, sollten die Module Richtung Süden ausgerichtet sein, um den höchsten Stromertrag zu erzielen. Allerdings lassen sich die örtlichen Gegebenheiten bei der Installation der Solarpanele nicht ignorieren. Vor allem Solaranlagen, die für den Eigenbedarf installiert wurden, sind häufig auf Dächern befestigt. Allein aus Sicherheitsgründen werden die Solarmodule in aller Regel flach auf den Dachziegeln des Schrägdachs montiert, da ansonsten starker Wind die Module aus ihrer Befestigung reißen könnte. Folglich gibt die Ausrichtung des Gebäudes in vielen Fällen die Ausrichtung der Solarmodule ohne großen Spielraum vor. Konsequenz dessen ist, dass die Leistungsfähigkeit einer Solaranlage so vielfältig sein kann, wie die Bedachung von Häusern individuell ist.

Die Ausrichtung der Solarmodule hat nicht nur auf die gesamte erzeugte Strommenge Auswirkungen, des Weiteren führt sie dazu, dass Solaranlagen mit vergleichbarer Gesamtleistung zu unterschiedlichen Uhrzeiten kontrastiert Strom produzieren. Für die Netzstabilität ist es jedoch zwingend notwendig, dass kontinuierlich für eine gleichbleibende Spannung gesorgt wird. Folglich interessieren wir uns nicht nur für die kumulativ erzeugte Strommenge einer \ac{pv}-Anlage, weitaus spannender sind die Echtzeit-Vorhersagen. 

Sowohl die Ausrichtung der Solarmodule als auch die Umgebung der Anlage soll in das Modell einfließen, indem Uhr- und Jahreszeit zu der entsprechenden Strommenge festgehalten werden. Die Logik dahinter ist mit der Annahme verbunden, dass sich die beiden Faktoren durch Uhr- und Jahreszeit repräsentieren lassen, weil die Konstellationen wiederkehrend sind. Ein Haus oder ein Baum, der zwischen 11:14 und 11:46 Uhr Schatten auf die Solaranlage wirft, wird mit hoher Wahrscheinlichkeit die Stromproduktion der Solaranlage am nächsten Tag auf die gleiche Weise beeinträchtigen. Das Ziel der Forschung ist, dass das Datenmodell diesen Zusammenhang erkennt und eine niedrigere Stromproduktion prognostiziert als am Nachmittag, wenn ansonsten die gleichen Bedingungen vorliegen.

Die Jahreszeit bündelt mehrere Faktoren und nimmt somit Komplexität aus dem Modell, ohne dabei entscheidende Rahmenparameter zu vernachlässigen. Wie bereits erwähnt können sich die Umgebungsfaktoren über die Jahreszeiten hinweg verändern, zum anderen wandert die Sonne in einem anderen Winkel über die Solaranlage. Der Einstrahlungswinkel und die Umgebung sind entscheidend für die Stromproduktion und werden durch die Jahreszeit repräsentiert.

 Die Kalenderwoche scheint ein guter Kompromiss zu sein, um die verschiedenen Faktoren abzubilden. Der \textit{n-te} Tag des Jahres würde den Merkmalsraum des Modell deutlich vergrößern. Da die Dimension des Merkmals 1 bis 366 statt 1 bis 53 wäre, ist die Wahrscheinlichkeit, dass sich die einzelnen Datenpunkte in der Größe des Raums verlieren, deutlich höher. Die Elevation der Sonne unterliegt zwar einem ständigen Wandel, allerdings ist es äußerlich fraglich, ob die minimalen Differenzen zwischen den einzelnen Tagen für die Prognose der Stromerzeugung einer \ac{pv}-Anlage überhaupt bemerkbar sind.

 

\subsection{Nachgeführte Photovoltaikanlagen}
\label{subsec:tracked_systems}

Sogenannte nachgeführte \ac{pv}-Anlagen, in der Regel größere Freiflächenanlagen, folgen selbstständig und automatisiert dem Sonnenstand, wodurch die Solarstromproduktion gegenüber stationären Anlagen verbessert wird. Optimalerweise trifft das Sonnenlicht fortwährend senkrecht auf die Solarmodule. Um dies zu bewerkstelligen, wird der Neigungswinkel und/ oder die Ausrichtung nach der Himmelsrichtung an den aktuellen Sonnenstand angepasst. 

Die im letzten Unterkapitel genannten Faktoren werden aus dem Datenmodell mit der Begründung ausgeschlossen, da für jede Solaranlage ein eigenes Modell angelegt wird und somit bei gleichen Wetterbedingungen dieselben Ergebnisse erzielt werden. 
Sowohl die Leistungsfähigkeit, der Wirkungsgrad des Wechselrichters als auch die Umgebungsfaktoren sind nahezu feste Rahmenparameter. Bei nachgeführten \ac{pv}-Anlagen haben wir nun den Fall, dass sich ein wichtiger Faktor, die Position des Solarmoduls in Bezug auf die Sonne, stets verändert, ohne dass dies in den Eingabedaten des Modells bemerkbar ist. Um die Konsequenzen für unser Vorhersagemodell zu beurteilen, müssen wir zwischen zwei verschiedenen Methoden, um eine \ac{pv}-Anlage nachzuführen, unterscheiden. Zum einen gibt es die astronomische und die sensorische Steuerung von \ac{pv}-Anlagen. 

\subsubsection{Astronomisch nachgeführte Photovoltaikanlagen}

Bei der astronomischen Steuerung werden die Solarmodule kontinuierlich zur Sonne hin ausgerichtet, unabhängig von der Wolkendecke. In diesem Szenario ist die Ausrichtung der Solarmodule zwar dynamisch, allerdings wird mit Hilfe dieser Methode die Ausbeute der Stromproduktion stets auf die gleiche Art und Weise verbessert. Insofern macht es für das maschinelle Lernen keinen Unterschied, ob die Solaranlage stets zur Sonne gewandt oder statisch montiert ist. Den Sonderfall, dass die Getriebemotoren beschädigt sind und ausfallen, sei an dieser Stelle außen vorgelassen.

\subsubsection{Sensorisch nachgeführte Photovoltaikanlagen}

Spannender wird es bei der aufwendigeren Technologie, die einen lokal installierten Sensor die optimale Ausrichtung der Solarpanele ermitteln lässt. Der hellste Punkt am Himmel wird durch die Sensorsteuerung wahrgenommen und dementsprechend werden die Sonnenkollektoren ausgerichtet. Der hellste Punkt am Himmel kann sich jedoch sehr schnell ändern, da er von der aktuellen Wolkendecke abhängt. Vor allem bei einer durchwachsenen Wolkendecke lässt sich nur schwer ermitteln, ob die Solarpanelen im Moment von einer Wolke bedeckt werden. 

HIER: WOLKENKAMERA ERMÖGLICHT DIES, WEBSITE VERLINKEN

Folglich wird die Ausrichtung der Sonnenkollektoren durch den Sensor kontinuierlich an die aktuellen Gegebenheiten angepasst. Die exakte Wolkensituation unterliegt einer stetigen Veränderung und wird keineswegs durch die Eingabedaten der Realität entsprechend repräsentiert, wodurch Ungenauigkeiten bei der Prognose entstehen können.

Die gleiche Problematik besteht auch bei herkömmlichen Solaranlagen, deren Module nicht sensorgesteuert ausgerichtet werden. Insbesondere werden die für dieses Projekt zur Verfügung stehenden Wetterdaten  nicht in dem Intervall aktualisiert, indem sich die Wetterlage in der Wirklichkeit verändert. Da das Ziel dieser Arbeit ist, die gemittelte, erzeugte Strommenge stündlich vorauszusagen, soll uns die kontinuierlich schwankende Leistungsabgabe einer Solaranlage in der weiteren Beurteilung nicht tangieren. 

Inwiefern die Prognose bei durch einen Sensor nachgeführten \ac{pv}-Anlage verschlechtert wird, gilt es zu untersuchen. Da vor allem die sensorgesteuerte Variante der nachgeführten \ac{pv}-Anlagen auch mehrere Nachteile, wie höhere Installations- und Wartungskosten mit sich bringt, wird der Marktanteil solcher Anlagen als gering eingeschätzt. Folglich werden die Auswirkungen auf die Prognose nicht in dieser Arbeit untersucht.

\subsection{Wetter-abhängige Faktoren}

Verschiedene Wolkentypen wirken sich unterschiedlich auf die Sonneneinstrahlung aus. Zudem gehören Wolken zu den unbeständigen Faktoren, die sich sprunghaft auf die Stromerzeugung auswirken. Selbst wenn exakte, detailreiche Daten über die Bewölkung für die Analyse dieser Arbeit nicht vorliegen, soll der Effekt der unterschiedlichen Wolkentypen im folgenden kurz erläutert werden.

\subsubsection{Wolkenarten}
\label{subsubsec:clouds}

\begin{figure}
\centering
\def\svgwidth{425pt}
\input{assets/Cloud_types_en.pdf_tex}
\captionsetup{justification=raggedleft,singlelinecheck=false,skip=0pt}\caption*{\scriptsize{Quelle: \cite{pic:wikipedia}}}
\captionsetup{justification=centering,singlelinecheck=false,skip=25pt}
\caption{Wolkentypen}
\label{wolkentypen}
\end{figure}

%https://commons.wikimedia.org/w/index.php?search=cloud+types&title=Special:MediaSearch&go=Go&type=image

Stratuswolken sind flache, graue Wolken, die den Himmel oft bedecken. Sie bestehen aus Wassertröpfchen und liegen in niedriger Höhe. Stratuswolken blockieren die Sonneneinstrahlung und reduzieren die Helligkeit des Tageslichts erheblich. Sie haben eine kühlende Wirkung, da sie einen großen Teil der Sonnenenergie reflektieren.

Cumuluswolken sind große, weiße, flauschige Wolken mit einer flachen Basis und einer kuppelförmigen Oberseite. Sie treten oft an sonnigen Tagen auf. Cumuluswolken können die Sonneneinstrahlung beeinflussen, indem sie sie teilweise reflektieren und teilweise absorbieren. Dadurch entstehen Schatten und Sonnenflecken auf der Erdoberfläche.

Cirruswolken sind dünne, faserige Wolken, die in großen Höhen schweben. Sie bestehen aus Eiskristallen und erscheinen oft als Federwolken oder Schleierwolken. Cirruswolken lassen viel Sonnenlicht durch und haben daher eine geringere Auswirkung auf die Sonneneinstrahlung. Sie können jedoch einen Schleier vor der Sonne bilden und das Licht diffus erscheinen lassen.

Nimbostratuswolken sind dichte, graue Wolken, die mit starkem Niederschlag verbunden sind. Sie erstrecken sich über große Gebiete und sind oft mit anhaltendem Regen oder Schneefall verbunden. Nimbostratuswolken blockieren die Sonneneinstrahlung weitgehend und führen zu trüben, düsteren Bedingungen.

\subsubsection{Relative Luftfeuchtigkeit und Luftdruck}

Im Allgemeinen lässt sich sagen, dass die Teilchen (Wassertröpfchen, Eiskristalle, Staub, Pollen, Meeressalze und Schadstoffe), aus denen die Wolken bestehen, die Sonnenstrahlen reflektieren oder absorbieren. Auf die gleiche Weise können Wasser- und Luftpartikel in der unteren Troposphäre die Strahlung beeinflussen. Folglich ist die gemessene Luftfeuchtigkeit und der Luftdruck ein weiteres Kennzeichen dafür, wie viele Teilchen sich in der Troposphäre befinden. Umso höher die beiden Werte sind, desto größer ist die Wahrscheinlichkeit, dass die Sonneneinstrahlung reflektiert oder absorbiert wird, wodurch wir die Erwartungen an den Stromertrag senken müssen. 

\subsubsection{Temperatur}

Ein weit verbreiteter Glaube ist, dass die Stromproduktion durch Solaranlagen im Hochsommer am höchsten ist. In aller Regel ist dies jedoch nicht der Fall, da die Temperatur eine entscheidende Rolle spielt. Die hohen Temperaturen im Sommer beeinträchtigen den Wirkungsgrad der Solarzellen, welche die Schlüsselkomponente eines \ac{pv}-Systems bilden. Die meisten Hersteller geben einen Temperaturkoeffizienten an, der spezifiziert inwiefern sich der Wirkungsgrad mit steigenden Temperaturen verändert. Gewöhnlich erhöht sich der Widerstand im Stromkreis der Solarzelle mit den höheren Temperaturen, wodurch die Gesamtleistung der Anlage zurückgeht. Folgende Temperaturkoeffizienten sind aus dem Datenblatt der Solarmodule \textit{White} von dem renommierten, deutschen Solarmodulhersteller \textit{Meyer Burger} entnommen: \newline


\begin{table}[h]
\begin{center}
\def\arraystretch{1.5}
\setlength\tabcolsep{0.85cm}
\begin{tabular}{| l | c | r | c |}
\hline
Temperaturkoeffizient $I_{SC}$ &	$\alpha$ & 	$[\%/K]$ &		$+0,033$ \\ \hline
Temperaturkoeffizient $V_{OC}$ & 	$\beta$  &	$[\%/K]$ & 		$-0,234$ \\ \hline
Temperaturkoeffizient $P_{MPP}$ & 	$\gamma$  &	$[\%/K]$ & 		$-0,259$ \\ \hline
\end{tabular}
\end{center}

\captionsetup{justification=raggedleft,singlelinecheck=false,skip=-10pt}
\caption*{\scriptsize{Quelle: \cite{meyerburger}}}
\captionsetup{justification=centering,singlelinecheck=false,skip=25pt} 
\caption{Temperaturkoeffizienten Solarmodule Meyer Burger White}
\label{tab:temperaturkoeffizienten} 
\end{table}

% https://www.meyerburger.com/fileadmin/user_upload/PDFs/Produktdatenblaetter/DE/DS_Meyer_Burger_White_de.pdf

In \autoref{tab:temperaturkoeffizienten} ist ersichtlich, dass zwar der Kurzschlussstrom mit höherer Temperatur zunimmt, allerdings verringert sich die Leistung der Anlage. Dies ist am negativen Temperaturkoeffizienten der Leistung $P_{MPP}$ ersichtlich. Die Tatsache, dass auch die Wetter-abhängigen Faktoren sich unterschiedlich auf die Stromerzeugung einzelner Solaranlagen auswirken, bestärkt die Notwendigkeit für jede Solaranlage ein eigenes Modell anzulegen.

Des Weiteren kommt hinzu, dass bei manchen Solaranlagen ein Kühlmanagementsystem verbaut ist, das die Effizienz der Solarmodule steigert. Ebenso ist die Art der Befestigung in Bezug auf die Temperaturentwicklung von Interesse. So herrscht ein stärkerer Luftzug, wenn unter den Solarmodulen ein Freiraum ist. Durch die spürbaren Auswirkungen der heißen Temperaturen, müssten bei einem allgemeinen Modell zusätzlich zu der sich variierender Temperatur auch die Leistung des aktiven beziehungsweise passiven Kühlsystems berücksichtigt werden, wodurch selbstverständlich die Komplexität weiter in die Höhe getrieben werden würde. Auch an dieser Stelle sei erwähnt, dass die Kühlleistung des Systems und die Art der Montage in aller Regel statisch ist, weswegen wir sie nicht in den Eingabedaten unseres Datenmodells berücksichtigen müssen.

\subsubsection{Wind}

Wind kann als eine Art natürlicher Ventilator dienen. Die entstehende Luftbewegung um die Solarmodule trägt dazu dabei, dass stehende Hitze auf der Oberfläche der Panele abgeführt werden kann. Dies dient der Aufrechterhaltung niedriger Betriebstemperaturen und fördert somit die Effizienz der Anlage. Selbstverständlich hängt auch hier der Einfluss der Winde von den örtlichen Gegebenheiten ab. Luftschneisen können diesen Effekt verstärken, während umliegende Hindernisse den Luftstrom genauso blockieren können.

\subsubsection{Sonneneinstrahlung}

Die Sonne emittiert Energie in sämtliche Richtungen über den gesamten elektromagnetischen Strahlungsbereich. Ungefähr 20 Kilometer über der Erdoberfläche treffen im Mittel Sonnenstrahlung mit einer Energieflussdichte von $1367 W/M^2$ auf die Atmosphäre. Messungen im Weltraum haben gezeigt, dass dieser Wert nur geringfügig um vage 0,1\% über die letzten Jahrzehnte geschwankt ist, weswegen er als die \textit{Solarkonstante} betitelt wird. 

\begin{figure}
\centering
\def\svgwidth{350pt}
\input{assets/sonneneinstrahlung_deutschland.pdf_tex}
\caption{Sonneneinstrahlung Deutschland, Juli 2022}
\label{fig:sonneneinstrahlung}
\end {figure}

In \autoref{fig:sonneneinstrahlung} ist eine Karte von Deutschland zu sehen. Dargestellt wird die Monatssumme der Globalstrahlung. Deutlich zu erkennen ist, dass im Süden die Globalstrahlung im Mittel höher ist als im Norden. Folglich kommt die Sonnenstrahlung keineswegs gleichermaßen auf der Erdoberfläche an. Viele Faktoren tragen dazu bei, dass die Sonnenstrahlen unterschiedlich stark an verschiedenen Orten der Erdoberfläche auftreffen. Die Kugelform unseres Planeten ist der Grund, dass je höher der Breitengrad, desto flacher treffen die Sonnenstrahlen die Oberfläche der Erde, wodurch sich diese Strahlen auf eine größere Fläche verteilen. Auf die gleiche Weise wirkt sich die Topografie der Erde aus, wodurch es zu stärkeren, lokalen Unterschieden der Sonneneinstrahlung kommen kann.

Zum flacheren Einstrahlungswinkel in den höheren Breiten kommt hinzu, dass die Sonnenstrahlen eine größere Strecke zurücklegen müssen. Insbesondere auf dem letzten Abschnitt ihrer Reise, der Atmosphäre, kommen immer mehr Hindernisse wie Luftpartikel oder Wassertröpfchen hinzu, die die Strahlen reflektieren oder absorbieren können. Dass die Auswirkungen der Teilchen nicht zu unterschätzen ist, ist allein an der Temperaturabnahme bei zunehmender Höhenlage erkenntlich. Da die Energie der Sonnenstrahlen mit steigender Höhe von immer weniger Teilchen absorbiert werden kann, nimmt die Temperatur im Mittel $6,5 K/ 1 Kilometer$  ab, bis sie Zahlenwerte von unter $-50 ^\circ C$ an der Tropopause erreicht \cite{ws:dwd}.

%https://www.dwd.de/DE/wetter/thema_des_tages/2020/11/6.html

Die auf der Erde gemessene Globalstrahlung setzt sich aus der Diffusstrahlung und Direktstrahlung zusammen. Unter Diffusstrahlung versteht man jene Strahlung, die auf ihrem Weg von der Sonne zur Erde an anderen Atomen reflektiert und dadurch gestreut wurde. Direktstrahlung hingegen wurde nicht abgelenkt und ist dadurch intensiver und gebündelt. Während die Globalstrahlung schon seit geraumer Zeit protokolliert wird,  vermisst der \textit{Deutsche Wetterdienst} erst seit wenigen Jahren auf die horizontale Ebene bezogene Diffusstrahlung. Aus der Differenz der beiden wird die Direktstrahlung berechnet. 

\newpage

\section{Eigene Fragestellung und methodisches Vorgehen}

Um die zukünftigen Herausforderungen der Energieversorgung zu bewältigen, befasst sich diese Arbeit mit \ac{pv}-Anlagen als fluktuierende Stromerzeuger. Diese sollen möglichst optimal in das bestehende Stromnetz integriert werden. Die zentrale Fragestellung lautet hierbei, wie man präzise den erzeugten Solarstrom prognostizieren kann. Um dieses Ziel zu erreichen, sollen zuerst die entscheidenden Parameter ermittelt werden, die die Stromerzeugung einer Solaranlage beeinflussen. Allerdings liegt der Fokus ebenfalls darauf, dass die Berechnung der Prognose für beliebige \ac{pv}-Anlagen anwendbar ist, indem möglichst wenige spezifische Informationen über die Anlage in die Berechnung einfließen. Selbstverständlich spielen verschiedenste Eigenschaften der Solaranlage eine entscheidende Rolle, jedoch werden diese im Datenmodell nicht berücksichtigt. Schließlich sind diese spezifischen Informationen über die jeweiligen Solaranlagen in der Regel aufwendig zu beschaffen oder nicht in der notwendigen Qualität dokumentiert.

Zudem ermöglichen zunehmende Rechenkapazitäten und kostengünstigere Speichermöglichkeiten, dass für jede einzelne Solaranlage ein eigenes Datenmodell angelegt wird. Somit können die Gegebenheiten der \ac{pv}-Anlage, wie Quantität und Qualität der Solarpanele, vernachlässigt werden. Durch die Trainingsdaten ist das Datenmodell selbstständig in der Lage, die Leistungsfähigkeit der Solaranlage zu beurteilen. Das Modell wird fast ausschließlich von Wetterdaten trainiert, welche von verschiedenen Institutionen flächenmäßig und umfangreich aufgezeichnet werden. Die für das Trainieren des Lernalgorithmus benötigten Wetterdaten werden von der Website \textit{https://www.visualcrossing.com} extrahiert. Die Website bietet einen kostenfreien Zugang zu detaillierten historischen Wetterdaten der letzten 50 Jahre.

Das amerikanische nationale Labor für erneuerbare Energien (zu engl. \ac{nrel}), welches im Besitz des amerikanischen Energieministeriums ist, stellt eine groß angelegte Zeitreihen-Datenbank zu Verfügung, die System-Metadaten und Leistungswerte von sowohl experimentellen als auch öffentlichen, kommerziell genutzten Solaranlagen enthält.  Der Datensatz besteht aus einer Sammlung von Dateien, die jedem System zugeordnet sind. Die Metadaten umfassen Informationen über die Einzelheiten der Systemhardware und über den geografischen Standort. Diese Arbeit macht von diesen Datensätzen Gebrauch, um die Realisierbarkeit der eigenen Thesis zu überprüfen. 

Durch die Literaturrecherche sind bereits die relevanten Faktoren eingegrenzt, allerdings ist eine exakte Analyse der Daten unumgänglich. Hierbei soll vor allem beachtet werden, ob die Aufnahme des Merkmals einen solch starken Einfluss auf die Stromerzeugung hat, sodass die zunehmende Komplexität des Modells gerechtfertigt ist. Herausfordernd ist die Frage, ob die Informationen in manchen Merkmalen nicht bereits in anderen Merkmalen enthalten sind. Schließlich korrelieren einige Wetterdaten sehr stark miteinander. Ebenso gilt es zu überprüfen, ob sich die ausgewählten Merkmale auf unterschiedlichen Solaranlagen auf die gleiche Art und Weise auswirken. Um dies zu überprüfen, sollen mehrere Solaranlagen an verschiedenen Standorten ausgesucht und getestet werden.

Sofern es gelingt, sämtliche sich variierende Parameter herauszufinden, die die Solarproduktion beeinträchtigen, ist maschinelles Lernen eine vielversprechende Technologie um die Stromerzeugung zu prognostizieren. Insbesondere ist zu erwarten, dass sich das Spektrum der Trainingsdaten und das Spektrum während der Produktion (Inbetriebnahme) nicht groß voneinander unterscheiden werden.

Eine Unvollkommenheit im Datenmodell ist jedoch die Alterung der Solarzellen, welche dazu führt, dass die Leistungsfähigkeit über die Lebenszeit sich reduziert. Mögliche Konsequenzen wären ältere Daten kontinuierlich auszusortieren und das Modell mit den Neusten zu aktualisieren. Es ist davon auszugehen, dass der Alterungsprozess sich nur langsam in den Datensätzen bemerkbar machen wird, weshalb er die Ergebnisse über die kurze Zeitspanne eines Jahres kaum verfälschen sollte.

Um dieses Ziel zu erreichen, werden zuerst die Wetter- und Solardaten analysiert. Nachdem die Zusammenhänge innerhalb der Datensätze in \autoref{sec:features} erläutert werden, befassen wir uns in \autoref{sec:data_algorithm} damit, einen passenden Lernalgorithmus für diesen Anwendungsfall zu finden. Sobald ein geeigneter Lernalgorithmus gefunden wurde, thematisieren wir in \autoref{sec:data_algorithm}, wie die Daten für den gewählten Lernalgorithmus vorverarbeitet werden müssen. Schließlich erfordern die verschiedenen Lernalgorithmen eine unterschiedliche Datenvorverarbeitung. Dementsprechend ist es wichtig, diese mit dem erwählten Lernalgorithmus abzustimmen. In \autoref{sec:evaluation} soll die Leistungsfähigkeit des Modells beurteilt werden. Dazu betrachten wir vor allem den Determinierungskoeffizienten, der die Abweichung der prognostizierten von den tatsächlichen Werten widerspiegelt. Im letzten \fullref{sec:conclusion_outlook} wird der Mehrwert dieser Arbeit, insbesondere inwiefern sie dabei helfen kann Schwankungen im Stromnetz zu stabilisieren, diskutiert werden.
 
\newpage

\section{Untersuchte Photovoltaikanlagen}

Die in \autoref{tab:solarsystem_metadata} gelisteten Identifikationsnummern von \ac{pv}-Anlagen und den dazugehörigen Metadaten beziehen sich auf den Datensatz, der von der Webseite \url{https://data.openei.org/s3_viewer?bucket=oedi-data-lake&prefix=pvdaq} \newline stammt. Das \ac{nrel} bringt hervor, dass der Datensatz sowohl experimentelle als auch öffentliche, kommerziell genutzte \ac{pv}-Anlagen beinhaltet. Die Fläche aller Solarmodule der Anlage sowie die Nennleistung\footnote{Die Nennleistung gibt die maximale Leistung an, die eine \ac{pv}-Anlage erzeugen kann.} sind ein idealer Indikator, um die Funktion der Anlage einzuschätzen. Dies ist hilfreich um zu beweisen, dass die Prognose bei größeren Solarsystemen, die einen stärkeren Einfluss auf die Netzspannung haben, gleichermaßen funktioniert. Zwar ist die Funktionsweise unabhängig von der Größe und somit identisch, allerdings ist die Wertemenge der potentiell erzeugten Strommenge größer. Schließlich kann der erzeugte Solarstrom Werte zwischen $0 \ kW$ und der jeweiligen Nennleistung des Solarsystems einnehmen. 

Die \ac{pv}-Anlage mit der Identifikationsnummer $1201$ zählt mit einer installierten Nennleistung von $140,14 \ kW$ zu den größeren Solarstromlösungen. Um dies besser einordnen zu können, sei an dieser Stelle angemerkt, dass sich die Nennleistung von Solaranlagen auf meisten deutschen Einfamilienhäusern zwischen $4 - 10 \ \ac{kwp}$ \footnote{\textit{\ac{kwp}} ist eine Maßeinheit, die die Nennleistung einer \ac{pv}-Anlage unter den standardisierten Testbedingungen betitelt.} beläuft. In \fullref{sec:evaluation} wird die Leistungsfähigkeit des Prognosemodells für die \ac{pv}-Anlage $1201$ analysiert.


\begin{table}
\begin{center}
%\resizebox{\textwidth}{!}{
\begin{tabular}{| p{1.5cm} | p{1.5cm} | p{1.5cm} | p{2.3cm}  | p{2cm} | p{2.2cm} | p{2cm} |}
\hline
\ac{pv}-Anlagen ID & Fläche in $m^2$ & Nenn- leistung in $kW$ & Ausrichtung in Grad & Höhen- meter ü. NN & Koordinaten & Befestigung \\ \hline
  10 &  12,06 &   1,12 & 180 & 1792,8 & \ 39° 74' N \newline   105° 17' W & Fixiert \\ \hline
1199 & 366,54 &  52,92 & 180 &  325,0 & \ 39° 48' N \newline \  76° 66' W & Fixiert \\ \hline
1200 & 362,16 &  51,84 & 205 &  155,0 & \ 39° 19' N \newline \  76° 68' W & Fixiert \\ \hline
1220 &  45.67 &   8,54 & 180 &   75,0 & \ 40° 99' N \newline \  73° 66' W & Fixiert \\ \hline
1231 &  55,27 &   3,36 & 270 &    2,0 & \ 29° 02' N \newline \  80° 92' W & Fixiert \\ \hline
1244 &  23,28 &   3,24 & 186 &   10,0 & \ 30° 00' N \newline \  90° 09' W & Fixiert \\ \hline
1257 &  33,59 &   6,42 & 244 &   10,0 & \ 30° 00' N \newline \  90° 09' W & Fixiert \\ \hline

\end{tabular}
\end{center}
\caption{Metainformationen der Photovoltaikanlagen}
\label{tab:solarsystem_metadata} 
\end{table}

Der Ausrichtungsgrad der Solaranlage beschreibt in welche Himmelsrichtung die installierten Module gerichtet sind. Die Gradzahl 0 bedeutet, dass die Paneele genau Richtung Norden zeigen. 90° repräsentiert die Ausrichtung gegen Osten. Selbstverständlich weisen allerdings die meisten Solaranlagen Richtung Süden, wie es anhand der Zahlenspanne von 180 bis 270 innerhalb der Spalte \textit{Ausrichtung in Grad} in der \autoref{tab:solarsystem_metadata} zu erkennen ist.

In der Tabelle sind ebenfalls die Höhenmeter und die Art der Befestigung dokumentiert. In \fullref{subsec:tracked_systems} wurde bereits beschrieben, inwiefern die Befestigung die Stromproduktion einer Solaranlage beeinflussen kann. 

Durch die Höhenlage der Solaranlage lassen sich Rückschlüsse auf die Luftverhältnisse des Standortes ziehen. Schließlich nimmt mit steigender Höhe auf Grund der atmosphärischen Druckabnahme die Menge an Teilchen in der Luft \cite{ws:meteoschweiz}. Am Temperaturabfall und der maximalen Flughöhe von Hubschraubern wird erkenntlich, wie stark die Luftdichte als physikalischer Faktor unseren Alltag beeinflussen kann. Die Temperaturabnahme mit zunehmender Höhe liegt unter anderem an der Druckabnahme, wodurch sich die Teilchen leichter ausbreiten können und somit mehr Wärmeenergie durch die Ausdehnung in Bewegungsenergie umgewandelt wird. Zudem befinden sich weniger Teilchen in der Luft, die die Energie der Sonne absorbieren und somit in Wärme umwandeln können.

%https://www.meteoschweiz.admin.ch/wetter/wetter-und-klima-von-a-bis-z/temperatur/temperaturabnahme-mit-der-hoehe.html#:~:text=Aufsteigende%20warme%20Luft%20k%C3%BChlt%20ab,die%20aufsteigende%20Luft%20immer%20k%C3%BChler.

Die Leistung eines Hubschraubers wird ebenfalls auf Grund verschiedener Faktoren limitiert. Zum einem benötigt der Verbrennungsmotor des Flugkörpers Sauerstoff, um den Sauerstoff effizient verbrennen zu können, zum anderen ist die Luftdichte für den Auftrieb entscheidend. Durch die fallende Luftdichte nimmt ebenfalls die Auftriebskraft des Hubschraubers ab, bis sie schlussendlich nicht mehr groß genug ist, um das Eigengewicht zu tragen.

Im Kontext von \ac{pv}-Anlagen wird die Bedeutung von Luft durch die standardisierten Testbedingungen (zu engl. \ac{stc}) sichtbar, wodurch sich Solarmodule verschiedener Hersteller besser vergleichen lassen sollen. Diese standardisierten Testbedingungen geben vor, dass bei der Messung der Nennleistung die Solaranlage einer Einstrahlung von 1000 Watt pro Quadratmeter, einem Luftmassenverhältnis\footnote{Das Luftmassenverhältnis (AM-Verhältnis) ist ein Begriff, der in der Solarenergie und der atmosphärischen Optik verwendet wird. Es beschreibt, wie viel atmosphärische Masse die Sonnenstrahlen durchlaufen, wenn sie die Erdoberfläche erreichen. Ein Luftmassenverhältnis von 1,5 bedeutet, dass die Sonnenstrahlen 1,5-fach so viel Luftmasse durchlaufen, wie sie es tun würden, wenn die Sonne senkrecht über dem Beobachter steht.} von 1,5 und 25° C ausgesetzt ist.


\newpage

\section{Zusammenhänge der Merkmale}
\label{sec:features}

Die Qualität der Daten definiert maßgeblich die Leistungsfähigkeit des Prognose-Modells. Schließlich sind die Algorithmen im Bereich des maschinellen Lernens derart verallgemeinert, dass sie die Bedeutung der Daten nicht kennen müssen. Dies ist von enormen Vorteil, da so maschinelles Lernen viele Anwendungsmöglichkeiten, wie Klassifizierung von Spam und Phishing-Mails, Erkennung von Objekten anhand von Bildern, Schätzung eines Immobilienwertes oder eben die Prognose der Stromerzeugung einer \ac{pv}-Anlage, anbieten kann.

\subsection{Transformation der Daten zu Wissen}

Im heutigen Zeitalter werden Unmengen von Daten gesammelt, die sowohl strukturiert als auch unstrukturiert sein können. Die Stärke der selbstlernenden Algorithmen ist es Erkenntnisse aus einer gewaltigen Datenmenge zu ziehen und anhand der Muster, die sich in den Daten befinden, bestimmte Vorhersagen zu treffen. In diesem Kapitel sollen die Zusammenhänge zwischen den einzelnen Merkmalen\footnote{Als Merkmale werden im Folgenden jegliche Daten bezeichnet, die die Grundlage für die Prognose bilden. Sie werden in den Lernalgorithmus eingespeist, um daraus eine Vorhersage zu erhalten.} und der Zielvariablen\footnote{Als Zielvariable bezeichnen wir jenen Wert, für dessen wir eine Vorhersage treffen möchten.} im Detail betrachtet werden. Insbesondere ist es von Interesse, ob sich die zuvor beschriebenen Auswirkungen der Wetterfaktoren in den Datensätzen widerspiegeln.

Wie die Merkmale und die Zielvariable verknüpft sind, entscheidet über die Auswahl des passenden Lernalgorithmus. Im vorangehendem Kapitel wurden bereits die Auswirkungen einzelner Faktoren erläutert. Auf Grund der Gegebenheit, dass die exakten Auswirkungen nicht umfangreich erforscht sind, um sie beziffern zu können und sich zudem das gleiche Merkmal bei verschiedenen Solaranlagen unterschiedlich stark auswirken kann, ist ein Lernalgorithmus die richtige Wahl für diesen Anwendungsfall. Zusätzlichen müssen bei einem konventionellem Algorithmus\footnote{Für jeden Anwendungsfall werden bei einem konventionellem Algorithmus eine Reihe von Regeln festgelegt, die ein jeweiliger Programmierer umsetzt.} Informationen über die Spezifikationen der Solaranlage einfließen, wodurch die Programmierung des Algorithmus zunehmend komplexer wird.

Zuletzt gilt es zu überprüfen, wie stark die verschiedenen Merkmale tatsächlich mit der Zielvariablen korrelieren. Sofern manche Merkmale zu irrelevant sind und dementsprechend nur geringe Auswirkungen auf die Stromerzeugung haben, kann die Eliminierung dieser Merkmale zu einer Verbesserung der Leistungsfähigkeit des Lernalgorithmus führen. Dies gilt insbesondere, wenn nur ein kleiner Datensatz für die Erstellung eines Modells zur Verfügung steht. 

Um möglichst schnell für verschiedene Solaranlagen Prognosen erstellen zu können, könnte man zu Beginn absichtlich weniger relevante Merkmale ignorieren und sie erst zu einem späteren Zeitpunkt in das Modell einfließen lassen. Dies kann zu einer temporären Verbesserung der Ergebnisse führen.

\subsection{Heatmap}

\begin{figure}[H]
\centering
\def\svgwidth{375pt}
\input{assets/heatmap.pdf_tex}
\caption{Heatmap zur Visualisierung der Korrelationen zwischen den Merkmalen}
\label{fig:heatmap}
\end {figure}

Eine Heatmap ist ein schnell und einfach zu erstellendes Diagramm, das die Korrelationen zwischen den Merkmalen sowohl zueinander als auch zu der Zielvariablen aufzeigt. Die Zahlen auf den einzelnen Feldern, welche in \autoref{fig:heatmap} zu sehen sind, soll die Korrelation zwischen den jeweiligen zwei Variablen widerspiegeln, die auf der Höhe beziehungsweise Breite des Feldes zu sehen sind. Die Zahlenspanne beinhaltet Werte zwischen -1 und 1. Die entsprechenden Werte werden dabei wie folgt berechnet \cite{ws:vitalflux}:

\begin{equation}
r=\frac{\sum(x_i - \bar{x})(y_i - \bar{y})}
{\sqrt{\sum(x_i - \bar{x})^2\sum(y_i -  \bar{y})^2}}
\end{equation}

%https://vitalflux.com/correlation-heatmap-with-seaborn-pandas/

Aus der Gleichung wird ersichtlich, dass das Ergebnis maximal $(=1)$ wird, wenn die zwei Variablen $x$ und $y$ gleich stark steigen. Minimal hingegen wird das Ergebnis, wenn eine der Variablen steigt während die andere fällt. Der sogenannte \textit{Pearson Korrelationskoeffizient \textbf{r}} soll somit abbilden, wie stark zwei Variablen miteinander korrelieren. 

\subsubsection{Korrelation und Kausalität}

Anhand der Temperatur wird allerdings ersichtlich, dass die richtige Interpretation des Diagramms wichtig ist und teilweise die Aussagekraft nur sehr beschränkt ist. Wie wir wissen, leidet die Effizienz einer Solaranlage unter hohen Temperaturen. Dennoch vermittelt \autoref{fig:heatmap} den Eindruck, dass die Stromproduktion mit steigender Temperatur zunimmt. Schließlich haben die Temperatur und die erzeugte Solarenergie den Korrelationskoeffizienten 0.22. Jedoch darf man die Multikollinearität zwischen den anderen Faktoren nicht außer Acht lassen. So ergibt sich für die Temperatur und die Sonneneinstrahlung der Wert 0.42. Wie bekannt steigt die Temperatur mit erhöhter Sonneneinstrahlung. Häufig ist Korrelation nicht mit Kausalität gleichzusetzen.

Die tatsächliche Realität ist, dass Temperatur und Stromertrag einer \ac{pv}-Anlage einen negativen Korrelationskoeffizienten haben. Dies soll später genauer untersucht werden.

\subsubsection{Nicht-lineare Beziehungen}

Ein Korrelationskoeffizient, der sich im Nullbereich befindet, muss nicht unbedingt bedeuten, dass die zwei Variablen nicht miteinander korrelieren. Der Koeffizient spiegelt nur wieder, ob es zwischen den Variablen eine lineare Beziehung vorhanden ist. Selbstverständlich ist die Tageszeit ein gutes Indiz, um die Stromproduktion abzuschätzen. Nachdem die Sonne mittags ihren Zenit erreicht hat, fällt in der Regel die Stromproduktion wieder ab. Im Jahresdurchschnitt und etwas vereinfacht könnte die Beziehung zwischen Stromertrag und Uhrzeit durch eine umgedrehte Parabel beschrieben werden, wobei selbstverständlich diese unten abgeschnitten ist, da die Stromproduktion nicht negativ wird.

\subsection{Streudiagramm}

\begin{figure}
\centering
\def\svgwidth{450pt}
\input{assets/pairplot_all.pdf_tex}
\caption{Streudiagramme zur Visualisierung der Korrelationen zwischen den Merkmalen, zugehörig zur \ac{pv}-Anlage $1200$ in Linthicum, Maryland}
\label{fig:pairplot_all}
\end {figure}

Da im Gegensatz zu Computern Menschen visuelle Grafiken an Stelle einer mit Zahlen gefüllten Matrix besser verstehen können, sind Streudiagramme eine gute Herangehensweise, um die Zusammenhänge innerhalb des Datensatzes besser zu verstehen.

\autoref{fig:pairplot_all} zeigt die Daten einer Solaranlage in der Gemeinde Linthicum im Bundestaat Maryland\footnote{Maryland ist ein Bundesstaat an der Ostküste der Vereinigten Staaten von Amerika.} und die dazugehörigen Wetterdaten. Hier lässt sich die lineare Beziehung zwischen der Sonneneinstrahlung in der Nähe der Stadt Baltimore und dieser spezifischen Solaranlage beobachten. Allerdings sei an dieser Stelle erwähnt, dass nicht bei allen Solaranlagen das Streudiagramm ein solch deutliches Muster erkennen lässt. Dies kann auf verschiedene Gründe zurückführen werden. Wechselrichter oder Solarmodule mit einer niedrigeren beziehungsweise höheren Effizienz führen dazu, dass bei gleicher Sonneneinstrahlung unterschiedlich viel elektrische Energie produziert wird. Ebenso gilt es zu bedenken, dass die Wetterdaten von einem separaten Dienst verwendet werden. Es ist nicht garantiert, dass die Wetterstationen, die möglicherweise nicht exakt an diesem Standort stehen werden, für alle Orte auf der Welt die gleiche Qualität gewährleisten.

\subsubsection{Qualität der Daten}
\label{subsubsec:quality_data}

In der Diagonalen der \autoref{fig:pairplot_all} sind Balkendiagramme abgebildet, die die Verteilung der einzelnen Merkmale aufweisen. Besonders interessant ist hierbei das Balkendiagramm zum Bewölkungsgrad in Prozent. Die auffällige Verteilung spiegelt die in \fullref{subsubsec:clouds} bereits erwähnte Problematik, die Bewölkung am Himmel anhand einer Prozentzahl darzustellen, wider. Bei einem Index, der die Bewölkung einer Ortschaft wiedergeben soll, wird erwartet, dass die Verteilung keine größeren Lücken - insbesondere neben häufig vertretenen Messwerten - beinhaltet. Die Bewölkung ist von Ort zu Ort verschieden. So haben Städte in der Nähe von Flüssen in der Regel einen höheren Niederschlag, da sich über den Stadtflächen durch den Asphalt und die Betonflächen die Luft stärker erwärmt als über Grünflächen. Folglich verdunstet mehr Wasser, worauf die Wolken zu schwer werden und in Folge dessen abregnen. Das bedeutet, dass es kein einheitliches Schaubild gibt, das als Referenz verwendet werden kann. Dass einige Werte jedoch eklatant auftreten, währenddessen deren benachbarte Werte nicht in der Statistik vertreten sind, ist ein starkes Indiz dafür, dass es sich bei den Angaben zu der Bewölkung um Schätzwerte\footnote{Die Dokumentation des Wetterdienstleisters beschreibt den Wert wie folgt: "Die Wolkenbedeckung ist der Anteil des Himmels, der von Wolken bedeckt ist, ausgedrückt in Prozent. Die Wolkenbedeckung gilt für alle Höhenlagen. Die Tageswerte umfassen den Mittelwert der stündlichen Werte der Wolkenbedeckung."

Wie dieser Wert zu Stande kommt oder ob verschiedene Wolkentypen unterschiedlich bewertet werden, bleibt dabei unklar.} handelt.

Da bei den anderen Werten keine Auffälligkeiten zu verzeichnen sind und deren Messung vergleichsweise einfach und standardisiert ist, können wir davon ausgehen, dass sie vertrauenswürdig sind. Für den Bewölkungsgrad könnte es eine mögliche Konsequenz sein, ihn aus der Merkmalsliste des Lernalgorithmus zu streichen. Schließlich wird die Bewölkung zwar nicht vollständig, aber zumindest teilweise durch die zuverlässigeren Messwerte über die Feuchtigkeit und des Einstrahlungswertes repräsentiert. In \autoref{fig:pairplot_filtered} ist ersichtlich, dass eine höhere Feuchtigkeit mit mehr Bewölkung einhergeht. Gleichzeitig kommen infolge vermehrter Bewölkung weniger Sonnenstrahlen auf der Erdoberfläche an. 

\begin{figure}
\centering
\begin{minipage}[t]{0.45\linewidth}
\centering
\def\svgwidth{210pt}
\input{assets/histogram_cc_1220.pdf_tex}
\caption{Bewölkung in Port Chester bei New York City, New York}
\label{fig:histogram_cc_1220}
\end{minipage}
\hfill
\begin{minipage}[t]{0.45\linewidth}
\centering
\def\svgwidth{200pt}
\input{assets/histogram_cc_1231.pdf_tex}
\caption{Bewölkung in New Smyrna Beach bei Orlando, Florida}
\label{fig:histogram_cc_1231}
\end{minipage}
\end {figure}


Der Kontrast zwischen \autoref{fig:histogram_cc_1220} und \autoref{fig:histogram_cc_1231} könnte kaum deutlicher sein. Die Verteilung in beiden Histogrammen ist nicht gleichmäßig, allerdings sind die Balken in \autoref{fig:histogram_cc_1220} doch sehr auffällig. Die Werte häufen sich exakt an fünf Stellen. Das würde bedeuten, dass sich die Bewölkung in der Stadt Port Chester geradezu sprunghaft verändert. Selbst wenn die Werte nur in einem Zeitintervall von einer Stunde dokumentiert sind, ist die Wahrscheinlichkeit, dass der Wert die tatsächlichen Wetterbedingungen am Himmel widerspiegelt, gering.

Diese Auffälligkeiten konnten insgesamt an zwei von sieben Wetterstandorten beobachtet werden. Infolgedessen gilt es zu untersuchen, ob die Wetterdaten des jeweiligen Standortes für die Aufnahme in die Merkmalsmatrix qualifiziert sind. Schließlich kann der Bewölkungsgrad sowohl eine Bereicherung für die Prognose sein als auch ein Fluch, wenn es sich bei der Angabe um einen undifferenzierten Schätzwert handelt.

Die Validierung des Bewölkungsgrades soll ebenfalls automatisiert stattfinden. Dazu wird die Verteilung der Daten betrachtet, indem die Summe einmaliger Bewölkungswerte ausrechnet wird. Sofern die Summe einen Grenzwert unterschreitet, werden die Daten über den Bewölkungsgrad nicht validiert und schlussendlich aus der Merkmalsmatrix des Modells entfernt. 

Bestimmte Wetterstandorte sind für ihre Trockenheit beziehungsweise ihre überdurchschnittlich hohe Menge an Niederschlägen bekannt. Insofern ist es nicht für jeden Wetterstandort gegeben, dass der Minimalwert 0\% und der Maximalwert 100\% entspricht. Dies hat die Folge, dass die Verteilung für diesen Wetterstandort zwangsläufig geringer ausfällt.

Zudem muss der Grenzwert von der Größe des Datensatzes abhängig sein, da die Wahrscheinlichkeit, dass sich die gleichen Werte mehrfach wiederholen, mit der Größe der Datenmenge steigt.  Damit Wetterstandorte, zu denen nur wenige Daten gesammelt wurden, adäquat bewertet werden, muss bei diesen der Grenzwert herunter gesetzt werden. 
 
%Das Geburtstagsparadoxon besagt, dass ab einer Gruppe von 23 Personen die Wahrscheinlichkeit über 50\% beträgt, dass zwei Personen innerhalb dieser Gruppe am selben Tag ihren Geburtstag haben. Zwar sind die Geburtenraten über das Jahr ebenso nicht gleich verteilt, wie es auch die Bewölkungsgrade der verschiedenen Wetterstandorte es nicht sind. Allerdings sind bestimmte 

Insofern muss sowohl die Größe des Datensatzes als auch eine mögliche, ungleiche Verteilung auf Grund von umweltbedingten Faktoren berücksichtigt werden. Anhand des folgenden Programmiercodes in \autoref{lst:validate_cloudcover} soll die Validierung der Bewölkungsdaten erläutert werden. Vorerst betrachten wir dazu \autoref{eqn:logarithm}, wodurch die Bewertung des Algorithmus an die Größe des Datensatzes angepasst wird.

\begin{equation}
\label{eqn:logarithm}
h(x)=0.25\ln(15x+1)
\end{equation}

\autoref{fig:geogebra_cloudcover} zeigt die \autoref{eqn:logarithm} als Schaubild. Bei der Funktion handelt es sich um eine Logarithmusfunktion, die um den Wert 1 nach links verschoben wurde. Somit verläuft der Graph durch den Ursprung des Koordinatensystems. Zudem wird sie um den Faktor 15 in $x-$Richtung und den Faktor 0.25 in $y-$Richtung gestaucht.

\begin{figure}[h]
\centering
\def\svgwidth{425pt}
\input{assets/geogebra_cloudcover.pdf_tex}
\caption{Logarithmusfunktion}
\label{fig:geogebra_cloudcover}
\end {figure}

Die Logarithmusfunktion dient dazu, einen optimalen Grenzwert für unterschiedlich große Datensätze zu finden. Da die Wahrscheinlichkeit, dass sich gleiche Werte häufen, mit der Anzahl an Daten zunimmt und somit die Anzahl an Unikaten\footnote{Die Anzahl an Unikaten bezeichnet in diesem Kontext die Summe der unterschiedlichen Messwerte im Datensatz.} langsamer steigt, eignet sich die abnehmende, jedoch stets positive Steigung der Logarithmusfunktion, einen optimalen Grenzwert zu finden. Ab 3000 Messwerten wird der Grenzwert für die Mindestanzahl an Unikaten maximal. Sofern dieser Grenzwert nicht unterschritten wird, wird der Datensatz validiert und der Bewölkungsgrad in die Merkmalsmatrix aufgenommen. 

Im Programmcode ist ersichtlich, dass die Anzahl an Messdaten \textit{n\_sampes} durch 3000 geteilt und das Ergebnis der Division an die Logarithmusfunktion übergeben wird. Da die Variable \textit{n\_samples} auf 3000 begrenzt ist und \textit{n\_samples} nicht negativ werden kann, führt dies dazu, dass ausschließlich Zahlen zwischen 0 und 1 an die Logarithmusfunktion übergeben werden. Das Ergebnis der zuvor beschriebenen Logarithmusfunktion liegt zwischen 0.0 und 0.6931. Die anschließende Multiplikation mit 100 führt dazu, dass je nach Größe des Datensatzes unterschiedlich viele Unikate in diesem enthalten sein müssen. ab 3000 Messwerten gilt, dass mindestens 69 Unikate von dem Datensatz umfasst werden müssen.

Wie bereits zuvor erwähnt, gibt es Wetterstandorte, die zum Beispiel unter besonderer Trockenheit leiden. Da die Angabe über den Bewölkungsgrad nicht relativ ist, könnte dies bedeuten, dass für diese Standorte lediglich Messwerte zwischen 0 und 50 Prozent zu verzeichnen sind. Dementsprechend schneiden solche Wetterstandorte automatisch schlechter ab und könnten dadurch möglicherweise zu unrecht als mangelhaft markiert werden. Dieser Missstand kann ausgeglichen werden, indem das Minimum von dem Maximum der Messwerte subtrahiert wird. Eine darauf folgende Division durch 100 führt dazu, dass wir ein Ergebnis zwischen 0 und 1 erhalten. Der erhaltene Wert wird mit der zuvor errechneten Mindestanzahl an Unikaten multipliziert. 

In dem Beispiel, in dem ausschließlich Bewölkungswerte zwischen 0 und 50 Prozent auftreten, führt die Multiplikation mit dem Grenzwert und anschließende Neuzuweisung zu einer Halbierung jenes Grenzwertes. 

Sollte das Ergebnis unter dem Grenzwert liegen, so wird der Bewölkungsgrad aus der Merkmalsmatrix entfernt. Um das Ergebnis der Funktion zu evaluieren, wird  die Verteilung als Histogram dargestellt. 

\begin{lstlisting}[basicstyle=\small,label={lst:validate_cloudcover}, caption={Funktion zur Validierung der Bewölkungsdaten}]
def validate_cloudcover_quality(self):
        # max possible number of unique values is 100
        MAX_THRESHOLD = 100
	# MAX_THRESHOLD is maximized to 3000
        MAX_SAMPLES = 3000       
        
        def f(x):            
            return 0.25 * math.log(15*x +1)
        
        data = self.XY_df['cloudcoverage'].values        
        n_samples = min(len(data), MAX_SAMPLES)
        min_unique = f(n_samples/ MAX_SAMPLES) * MAX_THRESHOLD
        uniques = np.unique(data)
        # calculate the variety of cloudcoverage and weight it
        cc_variety_weight = (np.max(uniques) - np.min(uniques)) / 100
        min_unique = int(cc_variety_weight * min_unique)
        num_uniques = len(uniques)
        
        # plot histogram for test validation
        self.histogram_one_feature('cloudcoverage')
                
        if min_unique <= num_uniques:
            print("Cloudcoverage kept in features")
        else:
            # remove cloudcoverage from features
            self.features.remove('cloudcoverage')
            self.XY_df = self.XY_df.drop(columns=['cloudcoverage'])
            print("Cloudcoverage removed from features")
\end{lstlisting}



\subsubsection{Betrachtung der Daten im Detail}

Anhand der Kalenderwochen lässt sich ablesen, dass der für die Erstellung der Streudiagramme verwendete Datensatz die Zeitspanne eines halben Jahres umfasst. Durch die große Menge an Datenpunkte werden Streudiagramme, die zwei schwach miteinander korrelierende Variablen beinhalten, häufig unübersichtlich. Die vielen Datenpunkte im Diagramm färben das gesamte Schaubild ein, so dass sich kein Muster mehr erkennen lässt. Analog zur Heatmap kommt hinzu, dass die Sonneneinstrahlung andere Wetterfaktoren beeinflusst als auch selbst von diesen wiederum beeinflusst wird. Um Abhilfe zu schaffen, können die Daten gefiltert werden. Der Zusammenhang zwischen Sonneneinstrahlung und Stromproduktion ist gut erkenntlich. Ohne Zweifel besitzt dieses Merkmal die größte Hebelwirkung auf die Stromproduktion einer Solaranlage. Um besser die Auswirkungen der anderen Merkmale zu studieren, werden ausschließlich Datenreihen in denen der Einstrahlungswert zwischen 550 und 600 $W/ M^2$ liegt, betrachtet. Zuvor umfasste der Datensatz Werte von 0 bis zu 1000 $W/ M^2$.

\begin{figure}
\centering
\def\svgwidth{450pt}
\input{assets/pairplot_filtered.pdf_tex}
\caption{Streudiagramme zur Visualisierung der Korrelationen zwischen den Merkmalen bei einer Sonneneinstrahlung zwischen 550 und 600 $W/ M^2$}
\label{fig:pairplot_filtered}
\end {figure}

Wird nochmals die Korrelation zwischen der Temperatur und der Stromproduktion betrachtet, ist eine negative lineare Beziehung deutlich zu erkennen. Der negative Temperaturkoeffizient $P_MPP$ ist in der Heatmap ebenfalls ersichtlich, dort zeigt sich diesmal den Wert -0.68. Nachdem der Datensatz nach Datenreihen mit ähnlicher Sonneneinstrahlung gefiltert wurde, bilden Temperatur und Stromertrag den absolut höchsten Korrelationskoeffizienten innerhalb der Heatmap. Dementsprechend ist die Temperatur nach der Sonneneinstrahlung der zweitwichtigste Wetterfaktor. Die Temperatur nimmt insbesondere auf Grund ihres entgegengesetzten Effektes eine besondere Rolle für die Prognose der Stromproduktion ein. Das heißt der wichtigste Faktor, die Sonneneinstrahlung, hat einen positiven Korrelationskoeffizienten zu der Temperatur. Mit erhöhter Sonneneinstrahlung steigt die Temperatur, wobei die zunehmende Wärme selbst sich negativ auf die Stromerzeugung auswirkt und somit die Temperatur einen negativen Korrelationskoeffizienten in Bezug auf die Stromerzeugung besitzt. Dies gilt nicht für den Bewölkungsgrad oder die relative Luftfeuchtigkeit. Zwar haben diese beiden Wetterfaktoren ebenfalls einen negativen Korrelationskoeffizienten bezogen auf die Stromerzeugung, allerdings bleibt dieser auch in Bezug auf die Sonneneinstrahlung negativ.

\begin{figure}
\centering
\def\svgwidth{425pt}
\input{assets/pairplot_filtered_radiation_temperature_1200.pdf_tex}
\caption{Streudiagramme zur Visualisierung der Korrelationen zwischen den Merkmalen bei einer Sonneneinstrahlung zwischen 550-600 $W/ M^2$ und einer Temperatur zwischen 25°C-30°C}
\label{fig:pairplot_filtered_radiation_temperature_1200}
\end {figure}

Wie bereits zuvor erwähnt, können Windböen dabei helfen, die Wärme auf den Solarmodulen abzutransportieren und somit die Effizienz der Module erhöhen. Inwiefern dies tatsächlich der Fall ist, soll auf die gleiche Art untersucht werden. Folglich schauen wir uns Datenreihen mit ähnlicher Sonneneinstrahlung und einer geringen Temperaturschwankung an. Wie das zuvor betrachte Streudiagramm dient auch \autoref{fig:pairplot_filtered_radiation_temperature_1200} der Visualisierung der Zusammenhänge zwischen den Wetterfaktoren und der Solarstromerzeugung. Nachdem Datenreihen, die die beiden Kriterien Sonneneinstrahlung zwischen 850 und 1000 $W/ m^2$ und Temperatur zwischen 25°C und 30°C nicht erfüllen, gefiltert wurden, können wir die Beeinträchtigung durch den Wind besser analysieren. Die Daten, die im Streudiagramm enthalten sind, gehören zu der Solaranlage mit der Idenfikationsnummer $1200$, welche sich in Linthicum bei Baltimore, Maryland befindet. Obwohl die \ac{pv}-Anlage über eine Fläche von über 360 $m^2$ bei einer Nennleistung von 51,85 $kW$ umfasst und somit eine große Angriffsfläche für Wind bietet, lassen sich in dem Streudiagramm infolge höherer Windgeschwindigkeiten keine Veränderung in der Stromproduktion verzeichnen. 

%https://www.google.com/maps/place/1739+W+Nursery+Rd,+Linthicum+Heights,+MD+21090,+USA/@39.1957005,-76.6815477,201m/data=!3m1!1e3!4m6!3m5!1s0x89b7e28c89326b8b:0xbf3ac3b4e494e552!8m2!3d39.1958527!4d-76.6804761!16s%2Fg%2F11bw40qz24?entry=ttu

\begin{figure}
\centering
\def\svgwidth{425pt}
\input{assets/solarsystem_1200_picture.pdf_tex}
\captionsetup{justification=raggedleft,singlelinecheck=false,skip=0pt}
\caption*{\scriptsize{Quelle: \cite{pic:googlemaps}}}
\captionsetup{justification=centering,singlelinecheck=false,skip=15pt}
\caption{Dreidimensionale Darstellung des Hotels mit der \ac{pv}-Anlage $1200$ auf dem vorderen Flachdach}
\label{pic:solarsystem_1200_picture}
\end {figure}

Satellitenaufnahmen zeigen, dass die \ac{pv}-Anlage auf einem von mehreren verschieden hohen Flachdächern eines Hotels befestigt ist. Mit Hilfe von Aufnahmen von \textit{Google Street View} lässt sich erkennen, dass sich bis auf eine deutlich höhere Hauswand nördlich der Anlage keine weiteren Hindernisse befinden, die einen Windzug blockieren könnten.

Da bei anderen \ac{pv}-Anlagen ebenfalls keine Anzeichen in den Datensätzen gefunden werden konnten, dass ein starker Windzug bei hohen Temperaturen die Solarstromproduktion fördern könnte, soll der Wind nicht mit in die Merkmalsmatrix aufgenommen werden. Überlegungen, die Prognose zu optimieren, indem die gefühlte Temperatur oder die Temperatur innerhalb der Datenvorverarbeitung algorithmisch anzupassen sind, anstatt die gemessene beziehungsweise prognostizierte Temperatur als Merkmal zu verwenden, haben zu keinen besseren Ergebnissen geführt und wurden infolgedessen verworfen. Dies hätte den Vorteil gehabt, dass durch die regelbasierte Programmierung der Effekt des Windes stets in die theoretisch zu erwartende Richtung gelenkt wird. Da die Theorie praktisch in den analysierten Datensätzen nicht wiederzufinden ist, wird der Wind als Wetterfaktor gänzlich beiseite gelassen und nicht für die Prognose des Solarstroms verwendet.


\newpage

\section{Datenvorverarbeitung und Lernalgorithmus}
\label{sec:data_algorithm}

Die Datenvorverarbeitung und der Lernalgorithmus sind eng miteinander verknüpft und beide sind voneinander abhängig. Für das Modell müssen die Wetterdaten passend vorbereitet werden, wobei das ausgewählte Modell dabei vorgibt, inwiefern die Daten angeglichen werden müssen. 

\subsection{Datenvorverarbeitung}

Für die Untersuchung dieser Arbeit wurden einige Solaranlagen ausgewählt, um zu untersuchen, wie gut anhand von Wetterdaten sich die Solarstromproduktion prognostizieren lässt. Selbst bei den sieben Solaranlagen, die für diese Forschung verwendet wurden, konnte festgestellt werden, dass die Zusammenhänge zwischen den einzelnen Wettermerkmalen und der erzeugten Strommenge sehr unterschiedlich sein können.

\subsubsection{Korrelationen zwischen den Merkmalen abhängig von den Gegebenheiten der Photovoltaikanlage}

Beispielsweise wird die Jahreszeit und die sich damit ändernde Elevation der Sonne betrachtet. Zudem wird ein Augenmerk auf die in \fullref{subsec:tracked_systems} beschriebenen Eigenschaften solcher \ac{pv}-Anlagen geworfen. Astronomisch gesteuerte \ac{pv}-Anlagen können sich dem variierenden Höhenwinkel der Sonne in Bezug auf die Erdoberfläche anpassen. Demgemäß ist zu erwarten, dass sich die Jahreszeit als Faktor in der Merkmalsmatrix weniger stark bemerkbar macht im Vergleich zu fixierten Solarsystemen. 

Da die Zusammenhänge zwischen den Merkmalen und der Zielvariablen je nach Solaranlage unterschiedlich sind, wird ein Lernalgorithmus ausgewählt, der möglichst wenig Datenvorverarbeitung benötigt. Dies ist ein Beitrag zu dem Ziel dieser Arbeit, dass für beliebige Solaranlagen ein qualitativ hochwertiges Prognosemodell erstellt werden kann. Schließlich ist das Ziel dieser Arbeit nicht ein einziges Vorhersagemodell für sämtliche \ac{pv}-Anlagen zu generieren, sondern die Erstellung individueller Prognosemodelle automatisieren zu können.

Sinn und Zweck der Datenvorverarbeitung ist es, die Daten für den jeweiligen Lernalgorithmus zu optimieren, damit die Leistungsfähigkeit des Modells gesteigert werden kann. Zudem soll vermieden werden, dass Unstimmigkeiten innerhalb des Datensatzes die Ergebnisse des Modells verzerren oder gänzlich verfälschen.

\subsubsection{Ausreißer}
\label{subsubsec:outlier}

Selbst wenn für ein Entscheidungsbaum die Datenvorverarbeitung nicht zwingend notwendig, ist es dennoch zu empfehlen, Unstimmigkeiten in den Daten zu beseitigen.

Unstimmigkeiten innerhalb des Datensatzes werden als Ausreißer betitelt, da sie nicht zum Muster zwischen ihresgleichen und der Zielvariablen passen. Da solche Ausreißer unausweichlich und in sämtlichen Datensätzen auftauchen können, dürfen diese nicht unbeachtet bleiben. Ein möglicher Grund für etwaige Ausreißer kann ein defektes Bauteil des Solarsystems sein. Zum Beispiel ein Defekt im Wechselrichter könnte dazu führen, dass trotz idealer Wetterbedingungen die erzeugte Wechselspannung ausbleibt. Umso länger das Solarsystem nicht repariert wird und die verringerte Stromproduktion in den Trainingsdatensatz des Modells aufgenommen wird, desto wahrscheinlicher ist es, dass das Prognosemodell den Fehler verinnerlicht und die Kalenderwoche für die übermäßige Abweichung verantwortlich macht.
???
\subsection{Lernalgorithmus}

Die Konsequenz, dass die Zusammenhänge zwischen den Merkmalen und der Zielvariablen sehr verschieden sein können, ist es ein Modell auszuwählen, das für seine Kontingenz gegenüber der Datenvorverarbeitung bekannt ist. 

Ein Entscheidungsbaum \textit{zu engl.: decision tree} hat eine dem Flussdiagramm ähnliche Baumstruktur, in der je nach ausgewählter Hyperparameter alle möglichen Ergebnisse, Eingabekosten und Nutzen dargestellt werden können. Da das Modell sowohl für kategoriale als auch kontinuierliche Zielvariablen verwendet werden kann, eignet es sich für die Prognose verschiedener Solaranlagen. 

\subsubsection{Diskretisierung der Zielvariablen}

Die Bedingungen werden innerhalb der Entscheidungsknoten aufgestellt. Der Entscheidungsbaum wird so lange durchgegangen, bis man an einem Endknoten angelangt ist. Die Endknoten eines Binärbaums werden als Blätter bezeichnet, sie bilden das Ergebnis für die jeweiligen Eingabedaten ab. Folglich müssen die Bedingungen des Binärbaums von oben nach unten durchgegangen werden, um zu einem Ergebnis zu gelangen. Ein Binärbaum hat die Eigenschaften, dass er maximal $2^{n}$ Blätter besitzen kann, wobei $n$ für die Höhe des Baums steht. Da es nur so viele Ergebnisse wie Blätter geben kann, muss die Wertemenge der Zielvariablen diskretisiert werden. 

Die diskretisierten Werte werden standardmäßig so ausgewählt, dass der mittlere quadratische Fehler am geringsten ist \cite{ws:scikit}. Für die Berechnung des mittleren quadratischen Fehlers eines Blattes werden ausschließlich die Trainingswerte verwendet, die diesem Blatt zuvor zugeordnet wurden. Auf Grund des geringen Rechenaufwands genießt diese Straffunktion in vielen Bereichen der Informatik größere Beliebtheit. Schließlich genügt durch die Technik wie ein Computer Zahlen speichert eine anspruchslose Operation, explizit gesagt eine Bitverschiebung nach links, um das Quadrat einer Zahl auszurechnen. Somit ist diese Methode äußerst effizient um die Mitte zwischen zwei oder mehreren Punkten zu finden. Den mittleren quadratischen Fehler als Straffunktion zu verwenden birgt allerdings den Nachteil, dass Ausreißer die Vorhersage sehr stark verfälschen können, weshalb diese idealerweise aus dem für das Training zuständigen Datensatz entfernt werden.


%https://www.geeksforgeeks.org/python-decision-tree-regression-using-sklearn/

\subsubsection{Lineare Beziehungen}

Wie so häufig kommen mit den Vorteilen eines Modells auch Nachteile einher. Zu einem der vielen Vorteile von Entscheidungsbäumen gehört die leicht verständliche Darstellung der Entscheidungsprozesse. Das Modell lässt sich als Flussdiagramm darstellen, wodurch sich die Vorhersagen des Modells gut nachvollziehen lassen. Dies ist bei der Fehlersuche und der Interpretierbarkeit von großem Nutzen.

\begin{figure}
\centering
\def\svgwidth{350pt}
\input{assets/decisiontree_linear.pdf_tex}
\caption{Einfacher Entscheidungsbaum mit einem Merkmal und der Tiefe 2}
\label{fig:decisiontree_linear}
\end {figure}

Die Tatsache, dass nichtlineare Beziehungen gut erkannt werden können ist sowohl ein Nachteil als auch ein Vorteil. Viele der Wettermerkmale haben eine nicht-lineare Beziehung zu der erzeugten Strommenge einer Solaranlage. Vor allem sind die Beziehungen bei verschiedenen Solaranlagen unterschiedlich, wodurch die Vorverarbeitung der Daten sich als schwierig darstellt. Insofern ist es ein großer Vorteil, dass die Wetterdaten nicht modifiziert werden müssen. In \autoref{fig:decisiontree_linear} ist jedoch ersichtlich, wie schwer sich ein Entscheidungsbaum mit linearen Beziehungen, wie beim Fall $x=y$, tut. Der Entscheidungsbaum kann den Zusammenhang $x=y$ nicht nur sehr limitiert wiedergeben, des Weiteren wird bei gleicher Tiefe des Entscheidungsbaums der Fehler  unabdingbar und maßlos größer, sobald Vorhersagen zu Daten getroffen werden sollen, deren Erwartungswert der Zielvariablen außerhalb des Wertebereichs des Trainingsdatensatzes liegt. Das liegt daran, dass nach dem Trainieren des Modells die Menge der möglichen Ausgangswerte bestimmt und statisch ist. Betrachte man nochmals \autoref{fig:decisiontree_linear}, so wird ersichtlich, dass für $x>10$ stets $y=11$ prognostiziert wird. Da $x=y$ ist, würde ein optimales Modell für $x=111$ auch $y=111$ vorhersagen. Wie bereits erwähnt würde unser Modell $y=11$ prognostizieren, wodurch wir den quadratischen Fehler $100^{2}=10000$ erhalten. 

\subsubsection{Aufbau eines Entscheidungsbaums}
\label{subsubsec:decisiontree_structure}

Künstliche Intelligenz nimmt eine immer bedeutendere Rolle in unserer heutigen Gesellschaft ein. Bereiche unseres täglichen Lebens werden bereits durch sie erheblich erleichtert. Dennoch schreckt ein Teil der Gesellschaft vor den noch unerforschten Begleiterscheinungen der neuen Technologie zurück. Nicht selten sind die Ergebnisse dieser Algorithmen schwer zu verstehen, wodurch Ungewissheiten hervorgerufen werden. 
Ein Entscheidungsbaum ist ein Modell aus dem Bereich des maschinellem Lernens, welches wiederum ein Teilgebiet von künstlicher Intelligenz ist. Obwohl Entscheidungsbäume derzeit als äußerst mächtige Lernalgorithmen angesehen werden, sind ihre Prognosen äußerst leicht nachzuvollziehen. Im Grunde genommen ist ein Entscheidungsbaum eine Verkettung von \textit{Wenn-Sonst-Anweisungen}, die schlussendlich zum Ergebnis führen. 

\begin{figure}[H]
\centering
\def\svgwidth{425pt}
\input{assets/binary_tree_linthicum_zoom_v2.pdf_tex}
\caption{Ausschnitt des Entscheidungsbaums für die Prognose der Solaranlage in Linthicum, Maryland}
\label{fig:binary_tree_linthicum}
\end {figure}

Da der komplette Binärbaum mit der Tiefe 11 zu groß für eine Abbildung innerhalb dieser Arbeit ist, zeigt \autoref{fig:binary_tree_linthicum} einen kleinen Ausschnitt des Entscheidungsbaums für die Solaranlage in Linthicum, Maryland, welcher mit Hilfe des \textit{\ac{cart}-Algorithmus}\footnote{Die Funktion des \textit{\ac{cart}-Algorithmus} ist es, eine optimale zweiteilige Trennung zu finden, indem ein Merkmal und ein Grenzwert gesucht wird, wodurch der mittlere quadratische Fehler der zwei neuen Teilmengen minimal wird. Erstmals wurde dieser Algorithmus von Leo Breiman 1984 publiziert.} erstellt wurde. In der ersten Zeile eines jeden Knotenpunktes steht die \textit{Wenn-Sonst-Anweisung}, die den weiteren Verlauf bestimmt. Falls die Bedingung erfüllt wird, so wird die Bedingung des linken Kinderknotens als nächstes überprüft, oder die des rechten Kinderknotens, falls ihr nicht nachgekommen werden konnte. Dieses Verfahren dauert so lange an, bis das Ende des Binärbaums, einem sogenannten Blatt, erreicht wurde.

Das Feld \textit{squared\_error} gibt den mittleren quadratischen Fehler, der sich in diesem Feld befindenden Proben in Bezug auf den Wert des Feldes an. Wie viele Proben des Trainingsdatensatz diese Bedingungen und demzufolge die darüber liegenden Bedingungen ebenso erfüllen, lässt sich aus den Knotenpunkten ablesen. Der dort zu sehende Wert wäre die Prognose für die jeweiligen Datenreihen, wenn der Knotenpunkt keine Kinderknoten mehr hätte.

Die Zusammenhänge zwischen den Merkmalen und der Zielvariablen konnten weitestgehend gut nachgebildet werden. So wird die Prognose jedes mal herunter gesetzt, wenn die Sonneneinstrahlung weniger wird. Genauso fällt die Prognose ohne Ausnahme, wenn die Bewölkung oder die Luftfeuchtigkeit zunimmt. 

Wie in \autoref{fig:binary_tree_linthicum} zu erkennen ist, sind die Auswirkungen der Temperatur dem Modell nicht gänzlich vertraut. Fällt die Temperatur unter 3,5° C, so wird die Prognose ebenfalls auf den Wert $4.369\ kW$ herabgesetzt. Bei vereinzelten Knotenpunkten des Entscheidungsbaums ist zu beobachten, dass eine niedrigere Temperatur zu einer geringeren Stromproduktion führt. Die Fehleinschätzung des Entscheidungsbaums ist vor allem dann anzutreffen, wenn der Grenzwert für die Temperatur besonders niedrig ist. Dies zeugt davon, dass die Multikollinearität zwischen Temperatur, Sonneneinstrahlung und Stromproduktion dem Entscheidungsbaum Schwierigkeiten bereitet. Da die Temperatur mit der Sonneneinstrahlung steigt, fehlinterpretiert der Algorithmus den Zusammenhang zwischen Temperatur und Stromproduktion. Da dies allerdings nur bei einem Teil der Knotenpunkte der Fall ist, soll die Temperatur nicht aus der Merkmalsmatrix ausgeschlossen werden. Unter dem Strich werden unter Berücksichtigung der Temperatur in Bezug auf die Prognose des Stromertrags dennoch bessere Ergebnisse erzielt. Dass die Temperatur ein wichtiger Parameter für die Prognose ist, liegt unter anderem daran, dass sie ebenfalls von verschiedenen Faktoren beeinträchtigt wird und somit, trotz der Korrelation zur Sonneneinstrahlung, nicht vernachlässigt werden darf. Zudem ist die Temperatur im Vergleich zur Sonneneinstrahlung viel träger.

Um ein besseres Verständnis für die Gewichtungen der einzelnen Merkmale zu bekommen, wird ein Histogram abgebildet, das die Anzahl der Verwendungen der einzelnen Merkmale bei den \textit{Wenn-Sonst-Anweisungen} darstellt.

\begin{figure}[H]
\centering
\fontsize{20}{20}\selectfont
\def\svgwidth{400pt}
\input{assets/histogram_feature_quantity.pdf_tex}
\caption{Verwendung der jeweiligen Merkmale im Entscheidungsbaum}
\label{fig:histogram_feature_quantity}
\end{figure}

Anhand der Häufigkeit, in der das Merkmal Sonneneinstrahlung auftritt, lässt sich die enorme Bedeutung für die Prognose der Stromerzeugung erahnen. Insbesondere die Tatsache, dass die Sonneneinstrahlung bei sämtlichen Modellen die Entscheidung für die obersten und somit grundlegendsten \textit{Wenn-Sonst-Anweisungen} bildet, verleiht dem Gewicht der Sonneneinstrahlung weiteren Nachdruck.



\subsubsection{Schlussfolgerungen für das Training des Modells}
\label{subsubsec:conclusion_for_training}

Aus dieser Eigenschaft von Entscheidungsbäumen müssen zwei Schlussfolgerungen für die Prognose über die Stromerzeugung von \ac{pv}-Anlagen gezogen werden. 

\paragraph{Schwierigkeiten bei unbekannten Werten.} 

Zum einem muss das Modell so lange trainiert werden, bis der Trainingsdatensatz alle möglichen Ausgangswerte der Zielvariablen beinhaltet. Da die Jahreszeit nicht nur eine erhebliche Rolle für die Vorhersage spielt, sondern den Maximalertrag eines Tages führend mitbestimmt, definiert sie folglich auch die Wertemenge der Zielvariablen. Somit sollte für jede Solaranlage mindestens ein Jahr lang Daten gesammelt werden. Gewiss kann das Modell bereits zuvor trainiert und für die Prognose verwendet werden, allerdings wird die Prognose weniger präzise, desto größer die Differenz zwischen den für das Training verwendeten Randwerten und den Test- beziehungsweise Produktionsdaten. Im Allgemeinen ist ein Entscheidungsbaum nicht gut darin, Vorhersagen für Daten zu treffen, die zuvor nicht im Raum des Trainingsdatensatzes waren.

\paragraph{Limitierte Wertemenge für mögliche Prognosen.}

Die zweite Schlussfolgerung bezieht sich auf die die unterschiedliche Leistung von Solaranlagen. Selbstverständlich haben \ac{pv}-Anlagen mit qualitativ und quantitativen unterschiedlichen Solarpanelen verschieden hohe Maximalerträge. Folglich ist die Wertemenge der möglichen Ausgangswerte einer \ac{pv}-Anlage von einem Eigenheim mit weniger Solarmodulen kleiner als die einer häufig größeren, kommerziell genutzten Anlage. Um bei größeren Anlagen die gleiche Auflösung in Bezug auf die Vorhersage zu erhalten, muss die Tiefe des Entscheidungsbaums zunehmen. Da diese die Anzahl der Blätter und somit die Anzahl der möglichen Werte auf direkte Weise steuert. Eine Konsequenz dessen ist, dass die Komplexität zunimmt und das Modell in der Regel einen größeren Trainingsdatensatz benötigt.

\newpage

\section{Optimierung der Hyperparameter}
\label{sec:hyperparameters}

Bei einem Entscheidungsbaum ist es auf Grund seiner Flexibilität gegenüber den verschiedenen Beziehungen zwischen den Merkmalen und der Zielvariablen von besonderer Wichtigkeit, die Hyperparameter entsprechend anzupassen. Wenn ein Entscheidungsbaum in seiner Flexibilität nicht angepasst wird, neigt er dazu, sich zu sehr an den Trainingsdatensatz anzupassen. Die Datenreihen des Trainingsdatensatz werden häufig perfekt abgebildet, sodass dieses Modell für den Trainingsdatensatz den Maximalwert bei der Evaluierung erzielt. In solchen Fällen schneiden zuvor unbekannte Daten, der sogenannte Testdatensatz, signifikant schlechter ab.

\subsection{Tiefe des Entscheidungsbaums}

\begin{figure}[H]
\centering
\def\svgwidth{350pt}
\input{assets/decisiontree_example_2.pdf_tex}
\caption{Einfacher Entscheidungsbaum mit 2 Merkmalen und der Tiefe 2}
\label{fig:decisiontree_example_2}
\end {figure}

Der Mensch verfügt über eine begrenzte Sinneswahrnehmung, weswegen er Schwierigkeiten dabei hat, sich Dimensionen jenseits von drei bildlich vorzustellen. Sie sind für sein Gehirn ein unvertrautes Konzept, da sie über die alltäglichen Erfahrungen hinausgehen und es ihm schlicht an Anschauungsobjekten mangelt. Stattdessen fordert es abstraktes Denkvermögen und mathematische Konzepte. Um ein besseres Verständnis von Entscheidungsbäumen und die Auswirkungen der Hyperparameter zu bekommen, wird zuerst das von einem Entscheidungsbaum erstellte Modell mit ausschließlich drei Dimensionen gestellt. Das in \autoref{fig:decisiontree_example_2} zu sehende Modell wurde mit der beschränkenden Eigenschaft, dass die Höhe des Entscheidungsbaums maximal zwei sein darf, erstellt. Folglich besitzt der Baum vier Blätter und somit vier mögliche Ausgangswerte für die Prognose. 

Die roten Punkte stellen die Trainingsdaten dar, die für die Erstellung des Modells verwendet wurden. Trotz der geringen Tiefe des Baums ist es dem Lernalgorithmus möglich, die Zusammenhänge der Variablen gut widerzuspiegeln.


\begin{figure}[H]
\centering
\def\svgwidth{350pt}
\input{assets/decisiontree_example.pdf_tex}
\caption{Einfacher Entscheidungsbaum mit 2 Merkmalen und der Tiefe 5}
\label{fig:decisiontree_example}
\end {figure}

\autoref{fig:decisiontree_example} zeigt zum Vergleich ein Modell eines Entscheidungsbaums der Tiefe fünf. Anhand des Schaubilds lässt sich erkennen, dass sämtliche Trainingsdatenpunkte exakt auf den Ebenen des Modells liegen. 

\subsection{Weitere Hyperparameter}

Sämtliche Hyperparameter haben den Sinn und Zweck, das Modell bezüglich der Anpassung an die Trainingsdaten zu beschränken. Im Folgenden sollen ein paar der wichtigsten Hyperparameter detaillierter erläutert werden.

\subsubsection{Mindestanzahl an Proben je Blatt} 

Die Mindestanzahl an Proben je Blatt entscheidet, wie viele Proben mindestens in einem Blatt enthalten sein müssen, damit die Existenz dieses Blattes und die des Bruder-Blattes berechtigt ist. Wenn die Bedingung nicht erfüllt, teilt der sich darüber liegende Knotenpunkt nicht weiter auf und wird selbst zum Blatt. Da die Auswirkung des Grenzwertes abhängig von der Größe des Datensatzes ist, ist es sinnvoll den Mindestwert ebenfalls abhängig von der Größe zu gestalten. Seit der Version 0.18 des Entscheidungsbaums aus der \textit{scikit-learn} Bibliothek ist es möglich eine Fließkommazahl als Parameter anzugeben, woraufhin diese mit der Anzahl der Datenreihen multipliziert wird und somit den Grenzwert bildet.

\subsubsection{Beschränkung der Merkmale}

Bei jedem Knotenpunkt wird neu entschieden, welches der Merkmale sich am besten eignet, um den Datensatz weiter zu unterteilen. Da an jedem Knotenpunkt ein anderes Merkmal das Beste sein könnte, um die Daten aufzuteilen, muss die Berechnung immer wieder erneut durchgeführt werden. Um die Rechenzeit zu verkürzen, lässt sich die Anzahl der zu berücksichtigenden Merkmale beschränken. Wenn die Anzahl der zu berücksichtigenden Merkmale limitiert werden soll, wird die maximale Anzahl an Merkmalen zufällig aus der Gesamtliste der Merkmale ausgewählt. 

An dieser Stelle sei angemerkt, dass ein sogenannter \textit{gieriger Algorithmus}\footnote{\textit{Gierige Algorithmen} entscheiden schrittweise über den nächstbesten Folgeschritt. Folglich können wir uns bei dem Ergebnis, welches durch den Algorithmus gefunden wurde, nicht sicher sein, dass es sich um das optimale Ergebnis handelt. Der Vorteil von dieser Art von Algorithmen ist es, dass sie vergleichsweise schnell und leicht zu implementieren sind. Zudem sind die Ergebnisse in der Regel gut genug, um den Anforderungen gerecht zu werden.} den Entscheidungsbaum erstellt. Für den Entscheidungsbaum bedeutet dies, dass bei jedem Knotenpunkt das momentan beste Merkmal aus der eventuell temporär begrenzten Merkmalsliste ausgewählt wird. Durch die Begrenzung der Merkmale kann es vorkommen, dass ein Merkmal nicht berücksichtigt wird, das zwar im aktuellen Schritt für die Teilung des Datensatzes das beste Ergebnis erzielt hätte, jedoch nicht für das optimale Endergebnis.

Ob dieses Szenario tatsächlich eintreten könnte, lässt sich nur schwerlich voraussagen. Dementsprechend soll für die Suche nach den besten Merkmalen für die optimale Teilung, die bei jedem Knotenpunkt im Entscheidungsbaum stattfindet, die zusätzliche Rechenzeit in Kauf genommen werden. Stattdessen beschränken wir die Rechenoperationen an anderer Stelle, indem wir die automatisierte Rastersuche auf die aus Erfahrung gut geeigneten Hyperparametern beschränken.

\subsubsection{Maximalanzahl an Blättern}

Die Maximalanzahl an Blättern ähnelt dem Parameter, der die maximale Höhe des Baums bestimmt. Schließlich lässt sich die Anzahl der Blätter bei einem vollständigem Binärbaum durch die Formel $n=2^h$ beschreiben. Folglich können beide Parameter sich gegenseitig aktiv beeinflussen, wobei die Maximalanzahl an Blättern ausschließlich Auswirkungen auf den Entscheidungsbaum hat, wenn die Zahl geringer ist als $n=2^h$.

Durch die Tatsache, dass es sich bei dem erstellten Entscheidungsbaum nicht zwingend um einen vollständigen Binärbaum handeln muss, können die zwei sehr ähnlichen Parameter den Entscheidungsbaum auf verschiedene Weise beeinträchtigen.
Zusätzlich dazu wurden Zahlen ausgewählt, die möglichst weit von der nächsten Zweierpotenz entfernt sind. So wird im Rahmen der Rastersuche nach den optimalen Parametern sichergestellt, dass voneinander differenzierte Entscheidungsbäume erstellt und überprüft werden.

%\subsubsection{Minimaler gewichteter Anteil der Proben}
%
%\subsubsection{Aufteilung der Proben}

\subsection{Hyperparameter auswählen}

Da im Vorhinein schwer zu beurteilen ist, welche Hyperparameter am besten zum jeweiligen Datensatz passen, ist eine Rastersuche eine Methode, um diese bestmöglichen Parameter zu finden. Eine Rastersuche ist ein Vorgehen, bei der mit roher Gewalt \textit{(zu engl.: brute-force)} versucht wird, die beste Kombination von Hyperparametern zu finden, indem alle Variationen durchprobiert werden.

Da die \textit{Brute-Force-Methode} mit erheblich mehr Rechenaufwand verbunden ist - schließlich muss für jede Kombination das Modell trainiert und evaluiert werden -, ist eine verkürzte Rastersuche eine beliebte Alternative. Dabei werden nicht alle Variationen durchprobiert, sondern eine zufällige Kombination verschiedener Hyperparameter getestet. Sofern man in Kauf nehmen kann, nicht das bestmögliche Ergebnis zu erzielen, kann durch die randomisierte Auswahl der Kombinationen an Hyperparametern erheblich Rechenzeit eingespart werden.

Um reproduzierbare Ergebnisse zu erhalten, verwenden wir die \textit{Brute-Force-Methode}, um die optimalen Parameter für das jeweilige Modell zu finden. Bei verschiedenen Solaranlagen wurden zwar unterschiedliche Kombinationen an Hyperparametern als optimal bewertet, allerdings waren diese selten weit voneinander entfernt. Folglich kann das Raster auf ein paar wenige Kombinationen reduziert werden und begrenzt damit den Rechenaufwand auf ein tolerierbares Ausmaß.

\autoref{tab:gridsearch} bildet die Hyperparameter ab, die für die automatisierte Suche nach den optimalen Parametern verwendet werden sollen. Die Auswahl der Zahlenreihen wurde getroffen, indem die gesamte Spanne der für optimal erachteten Hyperparametern der untersuchten Solaranlagen mit einem zusätzlichen Toleranzbereich repräsentiert werden. 

\begin{table}[H]
\begin{center}

%\resizebox{\textwidth}{!}{
\begin{tabular}{| p{4cm} | p{8cm} |}

\hline
Maximale Tiefe des Entscheidungsbaum & 5, 6, 7, 8, 9, 11, 12, 13, 15, 17 \\ \hline
Mindestanzahl an \newline Proben pro Blatt & 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 20, 25, 30, 35, 40, 45, 50 \\ \hline
Maximalanzahl \newline an Blättern & 35, 40, 48, 96, 192, 384, 768, 1536 \\ \hline

\end{tabular}
\end{center}

\caption{Potentielle Hyperparameter für die Rastersuche}
\label{tab:gridsearch}
\end{table}

\subsection{Hyperparameter der verwendeten Solaranlagen}

\begin{table}[h]
\begin{center}

\resizebox{\textwidth}{!}{
\begin{tabular}{| p{1.5cm} | p{2.1cm} | p{2cm} | p{2.2cm} | p{2cm} | p{1.6cm} | p{1.75cm} | p{2cm} |}
\hline
\ac{pv}-Anlagen ID & Daten- satz \newline (Training-/ Testgröße) & Maximal- betrag Stromerzeugung in $kW$ & Tiefe des \newline Entschei- \newline dungsbaum & Maximal-\newline anzahl Blätter & Mindest- anzahl Proben Blätter & R²-Wert\tablefootnote{Die Bezeichnungen R²-Wert und der Determinierungskoeffizient lassen sich als Synonyme auffassen.} \newline (Testen) & R²-Wert \newline (Trainieren) \\ \hline


  10 & 1392:640  &  1381 & 7 &   96 &  8 & 0.71 & 0.81 \\ \hline
1199 &  256:115  &  6905 & 5 &   48 & 10 & 0.89 & 0.93 \\ \hline
1200 & 1750:1750 & 46015 & 8 &   48 & 10 & 0.89 & 0.90 \\ \hline
1201 &  		 & 		 &   &		&    &      &      \\ \hline
1220 &  193:207  &  6816 & 5 &   48 &  9 & 0.75 & 0.84 \\ \hline
1231 & 1055:1055 &  2660 & 8 &   48 &  7 & 0.74 & 0.86 \\ \hline 
%\multicolumn{8}{|c|}{Keine Aufzeichnungen über die Sonneneinstrahlung vorhanden} \\ \hline
1244 & 	790:346  &  2691 & 6 &   48 &  9 & 0.67 & 0.78 \\ \hline % no solarradiation data
1257 & 	452:190  &   434 & 7 &   48 &  7 & 0.63 & 0.76 \\ \hline % no solarradiation data


\end{tabular}}
\end{center}
\caption{Hyperparameter der für diese Arbeit verwendeten Solaranlagen}
\label{tab:hyperparameters} 
\end{table}


Die Implementierung des Entscheidungsbaums aus der \textit{scikit-learn Bibliothek} ermöglicht es, eine Fließkommazahl als Wert für den Parameter \textit{Mindestanzahl an Proben pro Blatt} zu übergeben. Wie es anhand \autoref{eqn:min_samples_leaf} zu erkennen ist, ist der endgültige Wert von der Anzahl an Proben im Trainingsdatensatz abhängig. 

\begin{equation}
\label{eqn:min_samples_leaf}
min\_samples\_leaf=ceil(min\_samples\_leaf*n\_samples)
\end{equation}

Wie bereits in \fullref{subsubsec:conclusion_for_training} beschrieben, muss der Trainingsdatensatz und somit auch das Modell regelmäßig aktualisiert werden. Durch die Abhängigkeit des Parameters an die Größe des Datensatzes birgt sich die Hoffnung, dass ausschließlich das Modell und nicht auch dessen Hyperparameter angepasst werden müssen oder zumindest das Zeitintervall größer gestaltet werden kann. Letzten Endes müsste für die Anpassung der Hyperparameter eine erneute Rastersuche durchgeführt werden, welche mit erhöhtem Rechenaufwand verbunden ist.

Für viele Solaranlagen scheint die Beschränkung auf maximal 48 Blätter gut zu funktionieren. Der Entscheidungsbaum muss allerdings mindestens die Tiefe 6 besitzen, damit dieser Hyperparameter tatsächlich in die Gestaltung des Baums eingreift. Schließlich kann ein Binärbaum der Tiefe 5 höchstens 32 Blätter besitzen.

Die letzten beiden Solaranlagen $1244$ und $1257$ haben in der Evaluierung des Lernalgorithmus am schlechtesten abgeschnitten, allerdings sollte berücksichtigt werden, dass für den Wetterstandort der beiden \ac{pv}-Anlagen keine Aufzeichnung über die Sonneneinstrahlung zur Bestimmung der Solarstromproduktion zur Verfügung stand.

\newpage

\section{Evaluierung des Lernalgorithmus}
\label{sec:evaluation}

\subsection{Residuen}

Unter dem Begriff \textit{Residuen} betitelt man in der Regressionsanalyse die Abweichungen zwischen den prognostizierten und den tatsächlich aufgezeichneten Werten. \autoref{fig:residuals} stellt die Residuen der Solaranlage in Linthicum, Maryland dar. 

Mit einem solchem Diagramm lassen sich Auffälligkeiten in Bezug auf die Abweichungen erkennen, wodurch sich Fehler innerhalb unseres Modells aufspüren lassen. Schließlich deuten Muster in den Fehlern darauf hin, dass sich noch Informationen in den Datensätzen befinden. Informationen, die bisher noch nicht für die Vorhersage von Werten verwendet wurde. Lediglich eine zufällige Fehlerverteilung deutet daraufhin, dass sämtliche Informationen aus den zur Verfügung stehenden Daten extrahiert wurden. Durch den Vergleich des Trainings- mit dem Testdatensatz ist ebenfalls erkenntlich, ob bei dem erstellten Modell eine Überanpassungssituation\footnote{Man spricht im Kontext vom maschinellen Lernen von einer Überanpassung, wenn ein Modell die Details und Rauschen des Trainingsdatensatzes zu einem gewissen Grad erlernt, sodass es sich negativ auf die Leistungsfähigkeit des Modells bei zuvor unbekannten Daten auswirkt.} vorliegt.

%https://statologie.de/residuen/

\begin{figure}
\centering
\def\svgwidth{400pt}
\input{assets/residuals.pdf_tex}
\caption{Residuen }
\label{fig:residuals}
\end {figure}

\subsection{Vergleich Ist- und Soll-Wert}

Da der Determinierungskoeffizient zwar eine äußerst hilfreiche Methode ist, um die Leistungsfähigkeit des Modells zu bewerten, jedoch auf Grund seiner Einfachheit nur bedingt etwas über die Stärken und Schwächen des Modells verrät, stellen wir die tatsächlichen Prognosewerte und die dazugehörigen Ist-Werte nebeneinander dar. Für die Solaranlage in Linthicum im Bundesstaat Maryland erreichte das Prognosemodell beim Determinierungskoeffizienten, bezogen auf den Testdatensatz, Spitzwerte von bis zu 0.89. Ein Wert von 1 würde bedeuten, dass die Prognosewerte exakt mit den Ist-Werten übereinstimmen. 

\autoref{fig:predictions_linthicum} zeigt, dass an jedem Tag leichte Abweichung zwischen dem Ist- und dem Prognosewert zu verzeichnen sind. Auf der y-Achse ist die erzeugte Strommenge zu sehen, wohingegen die x-Achse das Datum des jeweiligen Tages\footnote{Der Grund für die lückenbehaftete Auflistung der einzelnen Tage liegt daran, dass der Datensatz randomisiert in einen Test- und Trainingsdatensatz aufgeteilt wird, wobei ausschließlich darauf geachtet wurde, dass Werte eines einzelnen Tages beisammen bleiben. Die Tage selbst wurden jedoch absichtlich untereinander gemischt, damit das Modell besser eingelernt werden kann und einen repräsentativen Trainingsdatensatz zur Verfügung hat. Folglich befinden sich die nicht abgebildeten Tage im Trainingsdatensatz.} darstellt. Einbrüche, welche auf Grund schlechterer Wetterbedingungen unausweichlich und normal sind, stimmen bei beiden Graphen überein. Dass die Vorhersagen des Prognosemodells nicht exakt mit den Ist-Werten übereinstimmen ist nicht überraschend noch war es eine Anforderung. Dass jedoch die ungefähre Solarstromproduktion prognostiziert werden kann und die Differenz hauptsächlich durch sehr viele kleine kumulierte Abweichungen verursacht wird, kann als Erfolg gewertet werden und belegt somit die Realisierbarkeit nachweislich.


\begin{figure}[H]
\centering
\def\svgwidth{400pt}
\input{assets/predictions_linthicum.pdf_tex}
\caption{Prognose und Ist-Werte des erzeugten Solarstroms einer Solaranlage in Linthicum, Maryland, USA}
\label{fig:predictions_linthicum}
\end {figure}

\subsection{Evaluierung einzelner Merkmale}

\subsubsection{Sonneneinstrahlung}

Unumstritten ist die Sonneneinstrahlung das wichtigste Merkmal für das Prognosemodell, um eine akkurate Aussage über die zu erwartende Solarstromproduktion zu treffen. Die Bedeutung von diesem Wetterfaktor wurde bereits in \fullref{subsubsec:decisiontree_structure} erläutert und ist durch die \autoref{fig:histogram_feature_quantity} klar ersichtlich. Ebenso wurde bereits des Öfteren erwähnt, dass die Wetterfaktoren sich gegenseitig untereinander beeinflussen. Dass diese Multikollinearität zwischen den verschieden Merkmalen auch von Nutzen sein kann, wird durch die beiden \ac{pv}-Anlagen mit der Indenfikationsnummer $1244$ und $1257$ bewiesen. In diesem Unterabschnitt sollen die Konsequenzen von unzureichenden Messwerten beziehungsweise Wetterprognosen über die Sonneneinstrahlung betrachtet werden. Denn die Datenbank von \ac{nrel} umfasst für die beiden \ac{pv}-Anlagen Messwerte für das Jahr 2014, allerdings sind für diese Zeitspanne und der jeweiligen Position der Anlage keine Werte über die Sonneneinstrahlung festgehalten. Die \ac{api} der Webseite \textit{wwww.visualcrossing.com} liefert für die Sonneneinstrahlung der beiden Orte Nullwerte. Der \ac{cart}-Algorithmus erkennt, dass hierdurch keine Aufteilung der Datenreihen möglich ist und ignoriert die Sonneneinstrahlung für die Erstellung des Entscheidungsbaums. Folglich wird das Merkmal bei keiner einzigen \textit{Wenn-Sonst-Anweisung} verwendet. Dennoch erzielen die beiden Prognosemodelle einen Determinierungskoeffizienten von bis zu $0.67$. \autoref{fig:predictions_1244} zeigt, dass die Gesamtdifferenz vor allem durch viele, kleinere Abweichungen entsteht. Dabei stellen die kumulierten Abweichungen die Aussagekraft des Modells schlechter dar als sie tatsächlich ist. 

Selbst wenn es ohne die Berücksichtigung der Sonneneinstrahlung gelingt, die Stromproduktion annähernd zu prognostizieren, ist es dennoch empfehlenswert sie zu berücksichtigen. Einbrüche in der Stromversorgung werden zwar erkannt, jedoch lässt sich der Wert mit einem Augenmerk auf die Sonnenstrahlung präziser bestimmen.

\begin{figure}
\centering
\def\svgwidth{400pt}
\input{assets/predictions_1244.pdf_tex}
\caption{Prognose und Ist-Werte des erzeugten Solarstroms einer Solaranlage in New Orleans, Louisiana, USA}
\label{fig:predictions_1244}
\end {figure}

Da nur sehr wenige Solaranlagen der Datenbank von \ac{nrel} aktuelle Solardaten beinhalten und über die \ac{api} von \textit{www.visualcrossing.com} keine historischen Wetter-Prognose-Daten abrufbar sind, wird die Prognose über den Solarstroms mittels tatsächlicher Wetterprognosen nicht getestet. Allerdings ist für die Netzstabilität die verfügbare Menge an Strom innerhalb der nächsten Stunden von besonderem Interesse. Erfreulicherweise ist die kurzzeitige Wetterprognose dank kontinuierlich verbesserter Wettersatelliten immer präziser geworden. Weiterhin ist es vorstellbar, dass die Prognose für die Sonneneinstrahlung nicht die gleiche Qualität wie die Vorhersage für andere Wetterfaktoren aufweist. Schließlich wird zwar die Menge der Sonnenstrahlen, die auf die Atmosphäre treffen, durch die Solarkonstante beschrieben, die unterschiedliche Messwerte über die Sonneneinstrahlung lassen sich somit auf die Einflüsse innerhalb der Atmosphäre zurückführen. Fehler in der Prognose über die Bewölkung, Feuchtigkeit oder Luftdichte führen demnach zu Folgefehlern in der Vorhersage über die Sonneneinstrahlung. Dementsprechend ist es von Vorteil, wenn sich die Vorhersage auf die Zuverlässigkeit anderer Faktoren ebenfalls stützen kann, ohne auf die Sonneneinstrahlung als Anhaltspunkt für die zu erwartende Solarstromproduktion gänzlich verzichten zu müssen.

\subsubsection{Bewölkungsgrad}

Die im \fullref{subsubsec:quality_data} zuvor geäußerten Bedenken, dass die Angaben des Wetterdienstes bezüglich des Bewölkungsgrades zu fragwürdig sind, sollen anhand der Evaluierung des Lernalgorithmus untersucht werden. Dazu wird das Modell einmal mit und einmal ohne den Bewölkungsgrad als Teil der Merkmalsmatrix trainiert. Anschließend werden die Determinierungskoeffizienten verglichen. Dabei gilt zu beachten, dass die Aufteilung des gesamten Datensatzes zu einem Test- und einem Trainingsdatensatz randomisiert stattfindet. Dadurch sind die Ergebnisse nicht reproduzierbar und die Evaluierung der unterschiedlichen Modelle nur bedingt vergleichbar. Hierfür werden die Datensätze in zwei gleich große Teilmengen aufgeteilt. So sinkt die Wahrscheinlichkeit, dass Ausreißer im Testdatensatz den mittleren quadratischen Fehler übermäßig verfälschen. Ausreißer im Trainingsdatensatz werden durch Hyperparameter wie die Mindestanzahl an Proben pro Blatt behandelt und das Modell dadurch geglättet. 

Zudem wird die Evaluierung mehrmals durchgeführt, wodurch mehrere Vergleichswerte erzielt werden. Wird der Bewölkungsgrad aus der Merkmalsmatrix außen vorgelassen, so wird für den Determinierungskoeffizienten des Entscheidungsbaums Werte zwischen 0.82 und 0.89 erhalten. Im Durchschnitt schneidet das Modell um 0.04 besser ab, als wenn der Bewölkungsgrad für die Prognose mitberücksichtigt wird. 

\subsection{Auffällige Abweichungen der Prognose}

Im \fullref{subsubsec:outlier} wurde bereits die Problematik von Ausreißern in den Datensätzen thematisiert und dass diese idealerweise vor dem Training des Lernalgorithmus aus dem Trainingsdatensatz entfernt werden sollten. Für das Training sind sie nicht von Interesse. Unstimmigkeiten zwischen der Prognose und den tatsächlichen Werten verdienen allerdings eine separate Analyse.

Insbesondere wenn diese Abweichungen an mehreren Tagen hintereinander auftreten, werden aus den Ausreißern viel eher Auffälligkeiten. Auffälligkeiten, die auf einen Defekt hindeuten und dementsprechend gesondert Aufmerksamkeit erfordern. Ein nicht funktionierender Wechselrichter reicht aus, um die Solarstromproduktion gänzlich zum Erliegen zu bringen. In diesem Fall verlieren die Betreiber der \ac{pv}-Anlage mit jeder vergangenen Stunde Geld. Umso schneller die Probleme erkannt werden, desto höher ist die Wirtschaftlichkeit der \ac{pv}-Anlage.

Zweifellos gibt es pragmatischere Lösungen als mittels maschinellem Lernen ein Prognosemodell anzulegen, um einen Totalausfall einer \ac{pv}-Anlage zu erkennen, die mit weniger Aufwand verbunden sind. Allerdings können genauso einzelne Solarmodule einen Defekt aufweisen, wodurch die Leistung der \ac{pv}-Anlage lediglich gemindert wird. 

Ein einziges defektes Solarmodul reicht jedoch aus, um die erheblichen Auswirkungen auf die Gesamtleistung der Anlage zu bemerken. Schließlich sind in einem Solarsystem in der Regel jeweils eine Gruppe von Solarmodulen, einem sogenannten Strang, in einer Reihenschaltung miteinander verknüpft. Die Verkettung der Module hilft dabei, den produzierten Strom effizient zum Wechselrichter zu leiten. Allerdings wird die Gesamtleistung des Strangs durch das schwächste Glied in der Kette bestimmt. Das defekte Solarmodul definiert den in diesem Strang maximal möglichen Stromfluss.

Anhand des Programmcodes in  \autoref{lst:discrepancies_detection} soll die Funktion zur Erkennung von Unstimmigkeiten beziehungsweise Defekten erläutert werden. Um Unstimmigkeiten zu erkennen, werden alle Tage separat betrachtet. An den jeweiligen Tagen wird ein Augenmerk auf den maximal zu erwartenden Stromertrag und dessen benachbarte Werte geworfen. Die lokale Funktion \textit{get\_mean\_maxima(data, indices)} liefert den Durchschnitt des Tagesmaximum und den Messwerten zwei Stunden vor und nach jenem Maximum. Analog dazu werden die korrespondierenden tatsächlichen Werte gemittelt.

Von besonderem Interesse sind jene Messwerte, bei denen der tatsächlich erzeugte Solarstrom signifikant unter dem jeweiligen Prognosewert liegt. Mittels der vektorisierten Division der tatsächlichen Werte durch die entsprechenden Prognosewerte werden größere Abweichungen erkannt. Wichtig ist, dass die tatsächlichen Daten den Dividend und die Prognosedaten den Divisor bilden. Relevant sind die Quotienten, die sich zwischen 0 und 1 befinden. Schließlich besagen sie, dass an diesem Tag weniger Solarstrom als erwartet produziert wurde.

Infolgedessen können Tage als auffällig markiert werden, wenn das Ergebnis der Division des tatsächlich erzeugten Solarstroms durch den Erwartungswert, einen bestimmten Grenzwert unterschreitet. Die Evaluierung von sieben verschiedenen \ac{pv}-Anlagen hat ergeben, dass nicht alle Modelle die gleiche Leistungsfähigkeit aufweisen. Demnach soll die Detektion von Auffälligkeiten in Abhängigkeit der Leistungsfähigkeit des Modells stehen. Die Leistungsfähigkeit eines Modells wird durch den Determinierungskoeffizienten repräsentiert. \autoref{eqn:determinationcoefficient} zeigt, wie der Determinierungskoeffizient berechnet wird.

\begin{equation}
\label{eqn:determinationcoefficient}
R^2=1-\frac{\sum_{i=0}^n(y_i\_true-y_i\_pred)^2}{\sum_{i=0}^n(y_i\_true-\bar{y}\_true)^2}
\end{equation}


Da sich für den Koeffizienten in den Untersuchungen dieser Arbeit Werte zwischen 0.6 und 0.9 ergeben, eignet sich dieser besonders gut als Grenzwert. Durch den höheren Grenzwert von besonders leistungsfähigen Modellen, können bei diesen die Unstimmigkeiten strenger bewertet werden. Die Anzahl an Falsch-Positiven-Ergebnissen\footnote{Falsch-Positive bezeichnen in diesem Kontext jene Tage, die als auffällig markiert wurden, obwohl kein Defekt der \ac{pv}-Anlage vorliegt.} kann dank des dynamischen Grenzwertes reduziert werden.

Ein Nachteil der Division der tatsächlichen Strommenge durch deren Erwartungswert ist, dass die absolute Abweichung an den jeweiligen Tagen abhängig von der zu erwartenden Stromproduktion bewertet wird. Dass heißt, wird an einem Tag auf Grund eines bewölkten Himmels eine geringere Stromproduktion prognostiziert, so wird die absolute Abweichung schneller als auffällig bewertet. Im Gegensatz dazu würde der gleiche absolute Fehler an einem sonnigen Tag - auf Grund des geringeren relativen Fehlers - für den Algorithmus nicht ungewöhnlich erscheinen. Grundsätzlich ist es allerdings nicht verkehrt, die Bewertungen der Abweichungen von der erwarteten Stromproduktion abhängig zu machen. Um die Unstimmigkeiten richtig zu klassifizieren, sollte sowohl der relative Fehler als auch der absolute Fehler berücksichtigt werden.  

Die verschiedenen Nennleistungen der Solaranlagen führen zu unterschiedlich großen, absoluten Residuen. Der zuvor beschriebene Missstand, dass kleine absolute Fehler an einem Tag mit einem niedrigen Erwartungswert schnell als auffällig bewertet werden, soll durch die lineare \autoref{eqn:linear} behoben werden. An die Funktion wird der Quotient, der sich durch die Division der Prognosedaten durch den Maximalbetrag der Prognosedaten ergibt, übergeben werden. Folglich wird der Grenzwert, den der relative Fehler nicht unterschreiten darf, an die für den Tag prognostizierte Stromproduktion angepasst.

\begin{equation}
\label{eqn:linear}
f(x)=0.3*x+0.5
\end{equation}

Relevant sind die $y-$Werte für Eingabewerte zwischen 0 und 1. Für 0 gibt die Funktion $f(x)$ 0.5 und für 1 den Wert 0.8 zurück. Demnach dürfen die Quotienten, je nach gemitteltem Tageswert, zwischen 20 und 50 Prozent unter dem Determinierungskoeffizieten des Modells liegen. Somit kann durch die lineare Gleichung $f(x)$ die Strenge des Algorithmus angepasst werden.

\newpage

\begin{lstlisting}[basicstyle=\small,label={lst:discrepancies_detection}, caption={Funktion zur Erkennung von Ausreißern}]
def find_discrepancies(self):
        # get the mean value for the maxima and its nearby values
        def get_mean_maxima(data, indices):
            avg_data = np.zeros(len(indices))
            for idx,indice in enumerate(indices):
                if indice > 1 and indice < len(data)-2:
                    avg_data[idx] = np.mean(data[indice-2:indice+3])
                else:
                    avg_data[idx] = data[indice]
            return avg_data
        
        def f(x):
            return 0.3*x +0.5
        
        # get local maxima indices
        maxima_indices = np.array(get_local_maxima_index_for_each_day(
            self.y_test_pred, hours=self.X_test[:,2]))
        
        actual_data = get_mean_maxima(self.y_test, maxima_indices)
        pred_data = get_mean_maxima(self.y_test_pred, maxima_indices)
        quotients = actual_data / pred_data
        # use r_2 score to evaluate the residuals
        r_2 = self.model.score(self.X_test, self.y_test)
        r_2 = r_2 * f(pred_data / np.max(pred_data))
        self.discrepancies_indices_test = maxima_indices[quotients < r_2]        
\end{lstlisting}

\begin{figure}[H]
\centering
\def\svgwidth{400pt}
\input{assets/predictions_outlier_1200.pdf_tex}
\caption{Erkannte Unstimmigkeiten im Testdatensatz der Solaranlage in Linthicum, Maryland, USA}
\label{fig:predictions_outlier_1200}
\end{figure}

\autoref{fig:predictions_outlier_1200} stellt die durch die Funktion lokalisierten Auffälligkeiten innerhalb des Testdatensatzes der Solaranlage mit der ID 1200. \autoref{fig:predictions_all_outlier_1200} hingegen zeigt die gesamte Solarstromprognose für den von der Funktion untersuchten Abschnitt. 

\begin{figure}[H]
\centering
\def\svgwidth{400pt}
\input{assets/predictions_all_outlier_1200.pdf_tex}
\caption{Prognose der Stromerzeugung für den Testdatensatz der Solaranlage in Linthicum, Maryland, USA}
\label{fig:predictions_all_outlier_1200}
\end{figure}

Fehlende Aufzeichnungen über Defekte der Solarsysteme schränken die fundierte Überprüfung der in \autoref{lst:discrepancies_detection} aufgeführten Funktion ein. Eine induktive Denkweise, die auf grundlegenden Prinzipien und bekannten Mustern basiert, führt zu der Annahme, dass bei den erkannten Unstimmigkeiten tatsächlich Defekte innerhalb des Solarsystems vorliegen. Der Vergleich zwischen \autoref{fig:predictions_all_outlier_1200} und \autoref{fig:predictions_outlier_1200} bringt hervor, dass sämtliche Auffälligkeiten durch die Funktion lokalisiert wurden.



\subsection{Prognose von bisher unbekannten Werten}


\begin{figure}[h]
\centering
\def\svgwidth{400pt}
\input{assets/predictions_forecast_1220_v2.pdf_tex}
\caption{Prognose für einen Zeitraum außerhalb des Trainingsdatensatzes}
\label{fig:predictions_forecast_1220}
\end{figure}

Unter \fullref{subsubsec:conclusion_for_training} wurde bereits angesprochen, dass Werte, die zuvor nicht im Trainingsdatensatzes enthalten waren, insbesondere bei dem \ac{cart}-Algorithmus problematisch sind. Da die Dauer der Datenerfassung nicht ein Jahr lang andauern soll, bevor das Modell für die Prognose zum Einsatz kommt, müssen Vorhersagen für Kalenderwochen getroffen werden, die nicht im Trainingsdatensatz enthalten waren. Die Kalenderwoche repräsentiert die Jahreszeit, welche wiederum mit der stetig ändernden Elevation der Sonne und somit auch dem Einstrahlungswinkel verknüpft ist.

In \autoref{fig:predictions_forecast_1220} ist die Prognose für die \ac{pv}-Anlage mit der Idenfikationsnummer $1220$ in Port Chester, New York zu sehen. Die Abbildung zeigt, dass die Residuen tendenziell, jedoch nur geringfügig größer sind als bei einem durchmischten Test-/ Trainingsdatensatz.

Die Evaluierung der Vorhersageleistung von bisher nicht erfassten Daten verdeutlicht zufriedenstellende Resultate. Dies bestätigt die Fähigkeit des Modells, Prognosen zu generieren, noch bevor ein vollständiges Jahr an Messdaten verfügbar ist. Dennoch empfiehlt es sich, eine Aktualisierung des Modells durchzuführen, um sicherzustellen, dass sämtliche Kalenderwochen im Trainingsdatensatz repräsentiert sind. In diesem Szenario erfolgte die Testauswertung ausschließlich auf Kalenderwochen, welche sich um genau zwei Wochen von den Extremwerten des Trainingsdatensatzes distanzieren. Die Gewährleistung verlässlicher Prognosen für Monatsabschnitte, die einen größeren zeitlichen Abstand aufweisen, bleibt dabei ungewiss.

%Ferner gilt es zu untersuchen, wie sehr die Abweichungen in der Wetterprognose sich auf die Qualität der Solarenergieprognose auswirken. Die \ac{api} des verwendeten Wetterdienstes bietet keine Aufzeichnung über die vergangenen Wettervorhersagen. Aktuelle Wetterprognosen können nicht verwendet werden, da für viele der \ac{pv}-Anlagen keine Daten aus dem Jahr 2023 vorhanden sind. Dementsprechend ist kein Testdatensatz zur Verfügung, um die Ergebnisse des Modells zu evaluieren.

\newpage

\section{Fazit und Ausblick}
\label{sec:conclusion_outlook}

Die Sonne scheint, die Vögel zwitschern und die Welt dreht sich weiter. Aber was passiert, wenn die Sonne nicht scheint? Was passiert, wenn wir auf erneuerbare Energien angewiesen sind, aber die Stromerzeugung durch die Photovoltaikanlagen ausbleibt? 

\subsection{Fazit}

In dieser Arbeit wurde untersucht, wie maschinelles Lernen dazu beitragen kann, die Prognose der Stromerzeugung von Solaranlagen zu verbessern und somit das Risiko von Stromausfällen zu minimieren. Dafür werden verschiedene Faktoren berücksichtigt, die die Stromproduktion einer Photovoltaikanlage beeinflussen. Dazu zählen zum Beispiel die Sonneneinstrahlung, der Bewölkungsgrad, die Temperatur und die Luftfeuchtigkeit.

Die Ergebnisse dieser Arbeit zeigen, dass die Prognose über die Stromerzeugung einer Photovoltaikanlage nicht nur realisierbar ist, ferner lässt sich die Erstellung von Vorhersage-Modellen für Photovoltaikanlagen mit unterschiedlichen Rahmenparametern automatisieren. Der Mehrwert dieser Arbeit besteht nicht nur darin, dass die Prognose dabei helfen kann, Spannungsschwankungen im Stromnetz zu stabilisieren. Des Weiteren können defekte Photovoltaikanlagen durch die Abweichung zwischen dem prognostizierten und dem tatsächlich erzeugten Solarstrom identifiziert werden.

Verschiedene Solaranlagen haben zwar unbeständige, jedoch nicht grundverschiedene Ergebnisse geliefert. Es ist davon auszugehen, dass die Ursache der Unbeständigkeit in der wechselhaften Qualität der Wetterdaten liegt. Schließlich lässt sich das Wetter über die Schnittstelle der Website \textit{www.visualcrossing.com} für sämtliche Ortschaften abfragen, jedoch ist eine detaillierte flächendeckende Aufzeichnung von einem einzigem Dienstleister als unwahrscheinlich einzustufen\footnote{Zur Kenntnisnahme: Der deutsche Wetterdienst (DWD) ist in Deutschland im Besitz von 83 Wetterstationen \cite{ws:dwdweatherstations}.}. Bedauerlicherweise ist die Entfernung zur nächsten Wetterstation nicht im Datensatz dokumentiert, gleichfalls lassen sich keine Informationen über mögliche Messabweisungen in den Datensätzen des Wetterdienstleisters finden.

%https://www.dwd.de/DE/leistungen/klimadatendeutschland/stationsuebersicht.html#:~:text=Wetter%20und%20Klima%20%2D%20Deutscher%20Wetterdienst,83%20Messstationen%20(nach%20Stationsname%20sortiert)

Sofern die Messwerte der Wetterstationen die tatsächliche Sonneneinstrahlung im Ort gut repräsentieren, lassen sich schon mit einem kleinen Trainingsdatensatz gute Prognosen erzielen. Bereits nach einem Monat kann ein Determinierungskoeffizient von bis zu 0.89 erreicht werden, wobei die Hälfte dieser Daten für den Testdatensatz abgezweigt wurden und somit der Trainingsdatensatz aus 15 zufälligen Tagen des Monats besteht. Dabei sollte allerdings nicht vergessen werden, dass die Komplexität des Modells mit mehr Daten aus unterschiedlichen Monaten zunimmt. Schließlich ist die Stromproduktion von der Jahreszeit abhängig. 

Um auch langfristig treffende Vorhersagen zu machen, muss das Modell selbstverständlich regelmäßig aktualisiert werden. Dies bedeutet im Detail, dass sowohl die Trainingsdaten erneuert als auch die Hyperparameter angepasst werden müssen. Um alle Jahreszeiten widerzuspiegeln, sollten die Trainingsdaten solange erneuert werden, bis ein ganzes Jahr erfasst wurde. Die Hyperparameter müssen aktualisiert werden, um der zunehmenden Komplexität gerecht zu werden. Vollends haben die Entscheidungsbäume, welche mit einem kleinen Datensatz trainiert wurden, in aller Regel eine geringere Tiefe, wodurch sich die mit der Anzahl der Daten steigende Komplexität belegen lässt.

Abschließend lässt sich sagen, dass die Realisierbarkeit dieser Thesis überprüft und bewiesen wurde. Die Erkenntnisse der Prognose sind vielseitig und verschiedene Anwendungszwecke sind denkbar. Jedoch sei angemerkt, dass diese Methode zur Bestimmung der zu erwartenden Stromproduktion nicht für die Überprüfung der Wirtschaftlichkeit einer geplanten \ac{pv}-Anlage dient. Für das Training des Lernalgorithmus sind stets Messwerte von dem bereits erzeugten Solarstrom mit dem dazugehörigen Zeitstempel erforderlich. Dementsprechend sind im Vorhinein keine Aussagen über die Leistungsfähigkeit einer noch nicht realisierten \ac{pv}-Anlage machbar.

\newpage

\subsection{Ausblick}
\label{subsec:outlook}

In einer Welt, die zunehmend von nachhaltigen Praktiken geprägt wird, hat sich die Solarenergie als Teillösung der Energiewende unter Beweis gestellt, die saubere, erneuerbare Energie verspricht. Die dynamische Natur der Solarenergieerzeugung stellt jedoch eine Herausforderung für die Netzstabilität dar, die bisher durch einen hohen Anteil an kontinuierlichen Energieerzeugern gewährleistet werden konnte. Durch die Nutzung fortschrittlicher Vorhersagemodelle für die Solarenergieerzeugung ergeben sich uns vielfältige Möglichkeiten, die über die Stabilisierung des Stromnetzes hinausgehen. Diese intelligenten Vorhersagen können nicht nur das Verbraucherverhalten verändern, sondern zudem den Unternehmen neue Möglichkeiten eröffnen und die Dynamik des Strommarktes neu gestalten.

Genaue Vorhersagen der Solarenergieproduktion ermöglichen es Netzbetreibern, die Energieverteilung zu planen und zu optimieren. Durch Informationen über den erzeugten Solarstrom können sie Angebot und Nachfrage im Stromnetz effizient ausgleichen und das Risiko von Stromausfällen und Netzstörungen minimieren. Intelligente Netztechnologien können sich in Echtzeit an Schwankungen der Solarleistung anpassen und andere erneuerbare Energiequellen und Speicherlösungen nahtlos integrieren. Diese Zuverlässigkeit und Anpassungsfähigkeit bilden die Grundlage für ein stabileres, widerstandsfähigeres und umweltfreundlicheres Stromnetz.

Eine öffentliche Einrichtung, die für Verbraucher einen Zugang zu Echtzeit-Solarenergieprognosen ermöglicht, verschafft wertvolle Erkenntnisse darüber, zu welcher Zeit mit günstigen Stromtarifen zu rechnen ist. Dieses Wissen ermöglicht es ihnen, ihre energieintensiven Aktivitäten so zu planen, dass sie mit den Spitzenwerten der Solarenergieproduktion übereinstimmen. Dadurch kann die gesamte Gesellschaft ihre Abhängigkeit von konventionellen Energiequellen verringern. Darüber hinaus ermöglicht die Transparenz der Solarenergieprognosen den Verbrauchern, umweltbewusste Entscheidungen zu treffen, was eine Kultur der Nachhaltigkeit fördert und die Akzeptanz von Solarenergielösungen erhöht. Ein simultaner Nutzen für ökologische Nachhaltigkeit und wirtschaftliche Ressourceneffizienz. Schließlich steht die Energie der Sonne in einem nahezu unbegrenzten Maß zur Verfügung, dazu begibt sie sich eigenständig in Form von elektromagnetischen Wellen auf den Weg zur Erdoberfläche. Dementsprechend entstehen anders als bei Gas-, Kohle- oder Atomkraftwerken weder Abbau-, Transport- oder Entsorgungskosten für die reine Energieressource. Schlussendlich werden sich die hohen Investitionskosten rechnen und im Falle einer gleichbleibenden Nachfrage an Strom resultiert die Transformation in einer Senkung der Stromkosten.

Ohne Zweifel verändert Solarenergie die Dynamik des Strommarktes. Dass der Einfluss der Solarenergie auf das Stromnetz berechenbarer wird, hilft sie als zuverlässige Energiequelle anzuerkennen. Dadurch kann das Vertrauen von Investoren gestärkt und Anreize für fortlaufende Investitionen in die Erneuerbaren geschafft werden. Mit der erhöhten Zuverlässigkeit geht eine Steigerung der Wettbewerbsfähigkeit gegenüber fossilen Brennstoffen einher. Dies ist förderlich, um das Herunterfahren klassischer Kraftwerke zu beschleunigen und die Transformation zu umweltfreundlichen Energiequellen zu vollbringen.

Die intelligente Nutzung von Solarenergievorhersagen gestaltet die gesamte Energielandschaft um. Von der Stabilisierung des Stromnetzes bis hin zur Beeinflussung des Verbraucherverhaltens und der Metamorphose des Energiemarktes, Prognosen beleuchten eine Zukunft, in der Nachhaltigkeit und Effizienz Hand in Hand gehen.

\cite{raschka2019python}

\cite{geron2022hands}

\cite{mueller2021machine}

\newpage

%\bibliographystyle{elsarticle-num}
\printbibliography

\end{document}


